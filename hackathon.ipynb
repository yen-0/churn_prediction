{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gymPOYTroHcm"
      },
      "source": [
        "# preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qNAm6YbmCuSF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "def train_model(X_train, y_train, model):\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "def predict_model(X_test, y_test, model):\n",
        "    pred_test = model.predict(X_test)\n",
        "    pred_test_proba = model.predict_proba(X_test)[:, 1]\n",
        "    predictions_test.append(pred_test_proba)\n",
        "    score = f1_score(y_test, pred_test)\n",
        "    report = classification_report(y_test, pred_test, zero_division=1)\n",
        "    return pred_test, pred_test_proba, score, report\n",
        "def create_kfold_datasets(X, y, n_splits=5, shuffle=True, random_state=None):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
        "    datasets = []\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "        datasets.append((X_train, X_test, y_train, y_test))\n",
        "    return datasets\n",
        "def plotit(y_test, y_probs):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
        "    plt.plot(thresholds, precision[:-1], label='Precision')\n",
        "    plt.plot(thresholds, recall[:-1], label='Recall')\n",
        "    plt.plot(thresholds, 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1]), label='F1')\n",
        "    plt.xlabel('Threshold')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Precision-Recall vs Threshold')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tuSzWSvwqpaR"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"train_data.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wP1WDondC32-"
      },
      "outputs": [],
      "source": [
        "if 'customerID' in df.columns:\n",
        "    df.drop('customerID', axis=1, inplace=True)\n",
        "if 'TotalCharges' in df.columns:\n",
        "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df.dropna(inplace=True)\n",
        "df['Contract'] = df['Contract'].map({'Month-to-month': 2, 'One year': 12, 'Two year': 24})\n",
        "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
        "df['Partner'] = df['Partner'].map({'Yes': 1, 'No': 0})\n",
        "df['Dependents'] = df['Dependents'].map({'Yes': 1, 'No': 0})\n",
        "df['PhoneService'] = df['PhoneService'].map({'Yes': 1, 'No': 0})\n",
        "df['MultipleLines'] = df['MultipleLines'].map({'Yes': 1, 'No': 0, 'No phone service': 0})\n",
        "df['OnlineSecurity'] = df['OnlineSecurity'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['OnlineBackup'] = df['OnlineBackup'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['DeviceProtection'] = df['DeviceProtection'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['TechSupport'] = df['TechSupport'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['StreamingTV'] = df['StreamingTV'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['StreamingMovies'] = df['StreamingMovies'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['PaperlessBilling'] = df['PaperlessBilling'].map({'Yes': 1, 'No': 0})\n",
        "df['gender'] = df['gender'].map({'Male': 1, 'Female': 0})\n",
        "df['PaymentMethod'] = df['PaymentMethod'].map({'Electronic check': 2, 'Mailed check': 1, 'Bank transfer (automatic)': 4, 'Credit card (automatic)': 3})\n",
        "df['InternetService'] = df['InternetService'].map({'Fiber optic': 2, 'DSL': 1, 'No':0})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDWdlL24yBQi"
      },
      "source": [
        "# VVVFeature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HGL_OYNsyFsv"
      },
      "outputs": [],
      "source": [
        "services = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
        "            'StreamingTV', 'StreamingMovies']\n",
        "df['num_services'] = df[services].sum(axis=1)\n",
        "df['revenue_proxy'] = df['MonthlyCharges'] * df['tenure']\n",
        "df['contract_tenure'] = df['Contract'] * df['tenure']\n",
        "df['tenure_squared'] = df['tenure'] ** 2\n",
        "df['tenure_cubed'] = df['tenure'] ** 3\n",
        "df['is_MTM'] = (df['Contract'] == 3).astype(int) # Assuming 3 represents Month-to-month\n",
        "df['high_charge'] = (df['MonthlyCharges'] > df['MonthlyCharges'].mean()).astype(int)\n",
        "df['MTM_high_charge'] = df['is_MTM'] * df['high_charge']\n",
        "df['log_TotalCharges'] = np.log1p(df['TotalCharges'])\n",
        "df['log_tenure'] = np.log1p(df['tenure'])\n",
        "df['log_MonthlyCharges'] = np.log1p(df['MonthlyCharges'])\n",
        "df['log_num_services'] = np.log1p(df['num_services'])\n",
        "df['log_revenue_proxy'] = np.log1p(df['revenue_proxy'])\n",
        "df['log_contract_tenure'] = np.log1p(df['contract_tenure'])\n",
        "df['log_MTM_high_charge'] = np.log1p(df['MTM_high_charge'])\n",
        "df['log_age'] = np.log1p(df['SeniorCitizen'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Auk1ylrmkiXR"
      },
      "outputs": [],
      "source": [
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "datasets = create_kfold_datasets(X, y, n_splits=5, random_state=42)\n",
        "predictions_test = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROMYsPS7erBP"
      },
      "source": [
        "# 1 Logistic Regression ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-MqNxyze1iX",
        "outputId": "906705fc-0105-4e7e-cbb5-8d2451b2a8b4"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'datasets' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mprint\u001b[39m(report)\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (y_train_probs, y_probs)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m X_train, X_test, y_train, y_test \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdatasets\u001b[49m:\n\u001b[32m     40\u001b[39m     model1(X_train, X_test, y_train, y_test)\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'datasets' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "\n",
        "\n",
        "# Train and predict using k-fold cross-validation\n",
        "def model1(X_train, X_test, y_train, y_test):\n",
        "    log_reg = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, solver = 'saga', penalty = 'l1'))\n",
        "    log_reg2 = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, class_weight= 'balanced', solver = 'saga', penalty = 'l1'))\n",
        "    alpha = 0.8\n",
        "    beta = 0.5\n",
        "    trained_model = train_model(X_train, y_train, log_reg)\n",
        "    trained_model2 = train_model(X_train, y_train, log_reg2)\n",
        "    y_train_probs1 = trained_model.predict_proba(X_train)[:, 1]\n",
        "    y_train_probs2 = trained_model2.predict_proba(X_train)[:, 1]\n",
        "    y_train_probs = (alpha * y_train_probs1 + beta * y_train_probs2) / 2\n",
        "\n",
        "    y_probs1 = trained_model.predict_proba(X_test)[:, 1]\n",
        "    y_probs2 = trained_model2.predict_proba(X_test)[:, 1]\n",
        "    y_probs = ( alpha * y_probs1 + beta * y_probs2) / 2\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    threshold = thresholds[best_threshold_index]\n",
        "    print(f\"Best threshold: {threshold:.4f} with F1 score: {f1_scores_thresholds[best_threshold_index]:.4f}\")\n",
        "    y_pred = (y_probs >= threshold).astype(int)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    print(report)\n",
        "    return (y_train_probs, y_probs)\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model1(X_train, X_test, y_train, y_test)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzSzbdEAnjYv"
      },
      "source": [
        "# 2 Decision Tree Classifier ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AysLpHg_ngqJ",
        "outputId": "21ad22aa-a5ff-4aca-aeae-bd5950ec9751"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.72      0.79       796\n",
            "           1       0.52      0.74      0.61       329\n",
            "\n",
            "    accuracy                           0.73      1125\n",
            "   macro avg       0.70      0.73      0.70      1125\n",
            "weighted avg       0.77      0.73      0.74      1125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "def model2(X_train, X_test, y_train, y_test):\n",
        "    dt_classifier = DecisionTreeClassifier(class_weight='balanced', max_depth=3, min_samples_leaf=1, min_samples_split=2)\n",
        "    trained_dt_model = train_model(X_train, y_train, dt_classifier)\n",
        "    y_pred_dt, y_pred_proba_dt, score, report = predict_model(X_test, y_test, trained_dt_model)\n",
        "    y_train_pred_proba_dt = trained_dt_model.predict_proba(X_train)[:, 1]\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba_dt)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    threshold = thresholds[best_threshold_index]\n",
        "    print(classification_report(y_test, y_pred_dt))\n",
        "    return (y_train_pred_proba_dt, y_pred_proba_dt)\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model2(X_train, X_test, y_train, y_test)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIYGP3GeqD7N"
      },
      "source": [
        "# 3 Random Forest Classifier ✅\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nloV0sboGSU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHvsh6dCqL_4",
        "outputId": "a6139b6e-151b-49be-af5b-70d5f9e8bc6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.76      0.81       796\n",
            "           1       0.56      0.76      0.64       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.72      0.76      0.73      1125\n",
            "weighted avg       0.79      0.76      0.76      1125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#param_grid = {'n_estimators': [100, 200],'max_depth': [6, 10, None],'min_samples_leaf': [1, 5, 10],'class_weight': [None, 'balanced', {0:1.0, 1:2.5}]}\n",
        "#grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "\n",
        "\n",
        "def model3(X_train, X_test, y_train, y_test):\n",
        "    rf_classifier = RandomForestClassifier(random_state=42, class_weight='balanced', max_depth=6, min_samples_leaf=1, n_estimators=100)\n",
        "    trained_rf_model = train_model(X_train, y_train, rf_classifier)\n",
        "    y_pred_dt, y_pred_proba_dt, score, report = predict_model(X_test, y_test, trained_rf_model)\n",
        "    y_train_pred_proba_dt = trained_rf_model.predict_proba(X_train)[:, 1]\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba_dt)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    threshold = thresholds[best_threshold_index]\n",
        "    print(classification_report(y_test, y_pred_dt))\n",
        "    return (y_train_pred_proba_dt, y_pred_proba_dt)\n",
        "\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model3(X_train, X_test, y_train, y_test)\n",
        "    break\n",
        "#0.64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehHCwJg9svR9"
      },
      "source": [
        "# 4 Gradient Boosting Classifier ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHhGS_I0s13i",
        "outputId": "f86822f7-5e5a-412c-b175-aba911a3e037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.73      0.81       796\n",
            "           1       0.55      0.78      0.64       329\n",
            "\n",
            "    accuracy                           0.75      1125\n",
            "   macro avg       0.72      0.76      0.73      1125\n",
            "weighted avg       0.79      0.75      0.76      1125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def model4(X_train, X_test, y_train, y_test):\n",
        "    alpha = 0.8\n",
        "    beta = 0.9\n",
        "    sample_weights = np.where(y_train == 1, 2.5, 1.0)\n",
        "    model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "    model.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "    model2 = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=10, random_state=42)\n",
        "    model2.fit(X_train, y_train)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "    #y_pred = (y_proba >= threshold).astype(int)\n",
        "    y_proba2 = model2.predict_proba(X_test)[:, 1]\n",
        "    #y_pred2 = (y_proba2 >= threshold).astype(int)\n",
        "    y_proba3 = alpha * y_proba + beta * y_proba2\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_proba3)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    threshold = thresholds[best_threshold_index]\n",
        "    y_pred3 = (y_proba3 >= threshold).astype(int)\n",
        "\n",
        "    y_train_proba = model.predict_proba(X_train)[:, 1]\n",
        "    y_train_proba2 = model2.predict_proba(X_train)[:, 1]\n",
        "    y_train_proba3 = alpha * y_train_proba + beta * y_train_proba2\n",
        "    print(classification_report(y_test, y_pred3))\n",
        "    return (y_train_proba3, y_proba3)\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model4(X_train, X_test, y_train, y_test)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX9ZBBa3exOJ"
      },
      "source": [
        "# 5 GaussianNB() ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huWx0cQbyaHL",
        "outputId": "84b86f4d-3863-4af4-be2c-c5d6b284d459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83       796\n",
            "           1       0.59      0.60      0.60       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.71      0.72      0.71      1125\n",
            "weighted avg       0.76      0.76      0.76      1125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "def model5(X_train, X_test, y_train, y_test):\n",
        "    gnb = GaussianNB()\n",
        "    calibrated_gnb = CalibratedClassifierCV(gnb, method='sigmoid', cv=5)  # Use sigmoid calibration\n",
        "    calibrated_gnb.fit(X_train, y_train)\n",
        "    y_pred_proba = calibrated_gnb.predict_proba(X_test)[:, 1]\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "    y_train_pred = calibrated_gnb.predict_proba(X_train)[:, 1]\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    return (y_train_pred, y_pred_proba)\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model5(X_train, X_test, y_train, y_test)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGfm8Tsl0Pxe"
      },
      "source": [
        "    #6 K neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFp5I9ir0UBb",
        "outputId": "6cbd0593-acde-4a02-ca4d-c365cdb58c42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN Classifier:\n",
            "KNeighborsClassifier(metric='manhattan', n_neighbors=60, weights='distance')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.88      0.83       796\n",
            "           1       0.60      0.43      0.51       329\n",
            "\n",
            "    accuracy                           0.75      1125\n",
            "   macro avg       0.70      0.66      0.67      1125\n",
            "weighted avg       0.74      0.75      0.74      1125\n",
            "\n",
            "Best threshold for KNN: 0.2637954367830825\n",
            "KNN Classifier:\n",
            "KNeighborsClassifier(metric='manhattan', n_neighbors=60, weights='distance')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       831\n",
            "           1       0.58      0.46      0.51       294\n",
            "\n",
            "    accuracy                           0.77      1125\n",
            "   macro avg       0.70      0.67      0.68      1125\n",
            "weighted avg       0.76      0.77      0.76      1125\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-39cba84c2bc8>:23: RuntimeWarning: invalid value encountered in divide\n",
            "  f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best threshold for KNN: 0.9367707629710854\n",
            "KNN Classifier:\n",
            "KNeighborsClassifier(metric='manhattan', n_neighbors=60, weights='distance')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.91      0.87       834\n",
            "           1       0.65      0.44      0.53       291\n",
            "\n",
            "    accuracy                           0.79      1125\n",
            "   macro avg       0.73      0.68      0.70      1125\n",
            "weighted avg       0.78      0.79      0.78      1125\n",
            "\n",
            "Best threshold for KNN: 0.362505957152888\n",
            "KNN Classifier:\n",
            "KNeighborsClassifier(metric='manhattan', n_neighbors=60, weights='distance')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87       849\n",
            "           1       0.60      0.43      0.50       276\n",
            "\n",
            "    accuracy                           0.79      1125\n",
            "   macro avg       0.72      0.67      0.69      1125\n",
            "weighted avg       0.78      0.79      0.78      1125\n",
            "\n",
            "Best threshold for KNN: 0.3270350404849127\n",
            "KNN Classifier:\n",
            "KNeighborsClassifier(metric='manhattan', n_neighbors=60, weights='distance')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       818\n",
            "           1       0.61      0.52      0.56       306\n",
            "\n",
            "    accuracy                           0.78      1124\n",
            "   macro avg       0.72      0.70      0.70      1124\n",
            "weighted avg       0.77      0.78      0.77      1124\n",
            "\n",
            "Best threshold for KNN: 0.3658699837792592\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    param_grid = {\n",
        "        'n_neighbors': [60],  # Example values, adjust as needed\n",
        "        'weights': ['uniform', 'distance'],  # Example values\n",
        "        'metric': ['euclidean', 'manhattan']  # Example values\n",
        "    }\n",
        "    knn = KNeighborsClassifier()\n",
        "    grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='f1') # Use 5-fold cross-validation\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_knn = grid_search.best_estimator_\n",
        "    y_pred_knn = best_knn.predict(X_test)\n",
        "\n",
        "    print(\"KNN Classifier:\")\n",
        "    print(grid_search.best_estimator_)\n",
        "    print(classification_report(y_test, y_pred_knn))\n",
        "\n",
        "    # Find the best threshold for KNN\n",
        "    y_pred_proba_knn = best_knn.predict_proba(X_test)[:, 1]\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba_knn)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold_knn = thresholds[best_threshold_index]\n",
        "    print(f\"Best threshold for KNN: {best_threshold_knn}\")\n",
        "\n",
        "    # ... (Rest of your code within the loop)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3LQ1qGM3M4w"
      },
      "source": [
        "# 7 SVC (no idea now)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PkVGW4T3QRn"
      },
      "outputs": [],
      "source": [
        "# prompt: use svc and grid search to predict ytest\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "# Assuming X_train, X_test, y_train, y_test are defined from your k-fold\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    # Create an SVC classifier\n",
        "    svc = SVC(probability=True)  # Enable probability estimates\n",
        "\n",
        "    # Define the parameter grid for GridSearchCV\n",
        "    param_grid = {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf', 'poly'],\n",
        "        'gamma': ['scale', 'auto', 0.1, 1]\n",
        "    }\n",
        "\n",
        "    # Perform GridSearchCV to find the best hyperparameters\n",
        "    grid_search = GridSearchCV(svc, param_grid, scoring='f1')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best estimator (SVC model with the best hyperparameters)\n",
        "    best_svc = grid_search.best_estimator_\n",
        "\n",
        "    # Predict on the test set using the best SVC model\n",
        "    y_pred = best_svc.predict(X_test)\n",
        "    y_pred_proba = best_svc.predict_proba(X_test)[:,1]\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    print(f\"Best threshold for SVC: {best_threshold}\")\n",
        "    y_pred_thresh = (y_pred_proba >= best_threshold).astype(int)\n",
        "\n",
        "    print(classification_report(y_test, y_pred_thresh))\n",
        "\n",
        "    break #remove to run for all folds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj6bL5R5eNiq"
      },
      "source": [
        "# 8 XGBoost ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rigozv3eTBH",
        "outputId": "e234d89c-3969-4e7c-dab2-54da6637eed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.70      0.79       796\n",
            "           1       0.52      0.80      0.63       329\n",
            "\n",
            "    accuracy                           0.73      1125\n",
            "   macro avg       0.71      0.75      0.71      1125\n",
            "weighted avg       0.79      0.73      0.74      1125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "from sklearn.metrics import confusion_matrix\n",
        "def model8(X_train, X_test, y_train, y_test):\n",
        "    xgb_model = XGBClassifier(random_state=42)\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'subsample': [0.8, 1.0],  # Example values\n",
        "        'colsample_bytree': [0.8, 1.0], # Example values\n",
        "    }\n",
        "    grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='f1', cv=3, n_jobs=-1) # Use 3-fold to speed it up\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best estimator\n",
        "    best_xgb_model = grid_search.best_estimator_\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = best_xgb_model.predict(X_test)\n",
        "    y_pred_proba = best_xgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    y_pred_thresh = (y_pred_proba >= best_threshold).astype(int)\n",
        "    y_train_pred = best_xgb_model.predict_proba(X_train)[:, 1]\n",
        "    print(classification_report(y_test, y_pred_thresh))\n",
        "    return (y_train_pred, y_pred_proba)\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model8(X_train, X_test, y_train, y_test)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUit-iUFeT--"
      },
      "source": [
        "# 9 Extra trees ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eBx9HnIeWkv",
        "outputId": "dc7f459b-ba6e-4a6e-9505-b014f38a2efd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.72      0.80       796\n",
            "           1       0.54      0.82      0.65       329\n",
            "\n",
            "    accuracy                           0.75      1125\n",
            "   macro avg       0.72      0.77      0.73      1125\n",
            "weighted avg       0.80      0.75      0.76      1125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "\n",
        "def model9(X_train, X_test, y_train, y_test):\n",
        "    #et_model = ExtraTreesClassifier(random_state=42, class_weight = 'balanced')\n",
        "    best_et_model = ExtraTreesClassifier(random_state=42, class_weight='balanced', max_depth=10, min_samples_split=10, min_samples_leaf=2)\n",
        "    #best_et_model = ExtraTreesClassifier(random_state=42\n",
        "    '''param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4],\n",
        "    }\n",
        "    grid_search = GridSearchCV(estimator=et_model, param_grid=param_grid, scoring='f1', cv=3, n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_et_model = grid_search.best_estimator_'''\n",
        "    best_et_model.fit(X_train, y_train)\n",
        "    y_pred = best_et_model.predict(X_test)\n",
        "    y_pred_proba = best_et_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Evaluate the model\n",
        "    #print(classification_report(y_test, y_pred))\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1]+1e-8)\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    #print(f\"Best threshold for ExtraTrees: {best_threshold}\")\n",
        "    y_pred_thresh = (y_pred_proba >= best_threshold).astype(int)\n",
        "    y_train_pred = best_et_model.predict_proba(X_train)[:, 1]\n",
        "    print(classification_report(y_test, y_pred_thresh))\n",
        "    return (y_train_pred, y_pred_proba)\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model9(X_train, X_test, y_train, y_test)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYR28i6ieW1l"
      },
      "source": [
        "# 10 MultiLayer Perception ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "466r3hMDebkU",
        "outputId": "48c10099-48b6-45b0-c0d8-13634fe35887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.51      0.66       796\n",
            "           1       0.43      0.91      0.59       329\n",
            "\n",
            "    accuracy                           0.63      1125\n",
            "   macro avg       0.68      0.71      0.62      1125\n",
            "weighted avg       0.78      0.63      0.64      1125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "'''param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (64,), (64, 32), (128, 64)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'solver': ['adam'],\n",
        "    'alpha': [0.0001, 0.001, 0.01, 0,1],\n",
        "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
        "    'learning_rate': ['constant', 'adaptive']\n",
        "}\n",
        "\n",
        "mlp = MLPClassifier(max_iter=500, random_state=42) # Increased max_iter\n",
        "grid_search = GridSearchCV(mlp, param_grid, scoring='f1', cv=3, n_jobs=-1) # Use 3-fold for speed'''\n",
        "\n",
        "def model10(X_train, X_test, y_train, y_test):\n",
        "    weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
        "    best_mlp = MLPClassifier(alpha=0.001, hidden_layer_sizes=(50,), max_iter=500,\n",
        "              random_state=42)\n",
        "    best_mlp.fit(X_train, y_train)\n",
        "\n",
        "    #best_mlp = grid_search.best_estimator_\n",
        "\n",
        "    y_pred = best_mlp.predict(X_test)\n",
        "    y_pred_proba = best_mlp.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    #print(classification_report(y_test, y_pred))\n",
        "    #print(best_mlp)\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    #print(f\"Best threshold for MLP: {best_threshold}\")\n",
        "    y_pred_thresh = (y_pred_proba >= best_threshold).astype(int)\n",
        "    y_train_pred = best_mlp.predict_proba(X_train)[:, 1]\n",
        "    print(classification_report(y_test, y_pred_thresh))\n",
        "    return (y_train_pred, y_pred_proba)\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model10(X_train, X_test, y_train, y_test)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhG89sXlecyi"
      },
      "source": [
        "# 11 Light GBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IftgRxerefkX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#!pip install lightgbm\n",
        "\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score, precision_recall_curve\n",
        "\n",
        "def model11(X_train, X_test, y_train, y_test):\n",
        "    '''param_grid = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'learning_rate': [0.01, 0.1],\n",
        "        'max_depth': [3, 5],\n",
        "        'num_leaves': [31, 50],\n",
        "        'min_child_samples': [20, 50],\n",
        "        'reg_alpha': [0, 0.1],\n",
        "        'reg_lambda': [0, 0.1],\n",
        "        'class_weight': ['balanced', None]\n",
        "    }\n",
        "    lgb_model = lgb.LGBMClassifier(random_state=42)\n",
        "    grid_search = GridSearchCV(estimator=lgb_model, param_grid=param_grid, scoring='f1', cv=3, n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_lgb_model = grid_search.best_estimator_'''\n",
        "\n",
        "    best_lgm_model = lgb.LGBMClassifier(class_weight='balanced', learning_rate=0.01, max_depth=5,\n",
        "               n_estimators=200, random_state=42, reg_alpha=0.1,\n",
        "               reg_lambda=0.1)\n",
        "    y_pred_proba = best_lgb_model.predict_proba(X_test)[:, 1]\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "\n",
        "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(best_lgb_model)\n",
        "\n",
        "    return y_pred_proba - best_threshold\n",
        "\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model11(X_train, X_test, y_train, y_test)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oI4_JbaegM3"
      },
      "source": [
        "# 12 Multinomial nb ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BI8mZZxekHJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "def model12(X_train, X_test, y_train, y_test):\n",
        "    mnb = MultinomialNB()\n",
        "    param_grid = {\n",
        "        'alpha': [0.1, 0.5, 1.0, 2.0],  # Laplace smoothing parameter\n",
        "        'fit_prior': [True, False],  # Whether to learn class prior probabilities\n",
        "        'class_prior': [\n",
        "          None,\n",
        "          [0.5, 0.5],\n",
        "          [0.7, 0.3],\n",
        "          [0.3, 0.7]\n",
        "        ]\n",
        "    }\n",
        "    grid_search = GridSearchCV(mnb, param_grid, scoring='f1', cv=5) # Use 5-fold cross-validation\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_mnb = grid_search.best_estimator_\n",
        "    print(best_mnb)\n",
        "\n",
        "    y_pred_proba = best_mnb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    print(f\"Best threshold for MultinomialNB: {best_threshold}\")\n",
        "\n",
        "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(best_mnb)\n",
        "    return y_pred_proba - best_threshold\n",
        "\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model12(X_train, X_test, y_train, y_test)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLUrXYfGekxO"
      },
      "source": [
        "# 13 Bernouli nb ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhyJrT3MymPr"
      },
      "outputs": [],
      "source": [
        "# prompt: use bernouli nb and grid search class weight to predict _test and maximize f1\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def model13(X_train, X_test, y_train, y_test):\n",
        "    bnb = BernoulliNB()\n",
        "    param_grid = {\n",
        "        'alpha': [0.1, 0.5, 1.0, 2.0],\n",
        "        'binarize': [0.0, 0.5, 1.0],\n",
        "        'fit_prior': [True, False],\n",
        "        'class_prior': [\n",
        "          None,\n",
        "          [0.5, 0.5],\n",
        "          [0.7, 0.3],\n",
        "          [0.3, 0.7]\n",
        "        ]\n",
        "    }\n",
        "    grid_search = GridSearchCV(bnb, param_grid, scoring='f1', cv=5)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_bnb = grid_search.best_estimator_\n",
        "    print(best_bnb)\n",
        "\n",
        "    y_pred_proba = best_bnb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    print(f\"Best threshold for BernoulliNB: {best_threshold}\")\n",
        "\n",
        "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    return y_pred_proba - best_threshold\n",
        "\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model13(X_train, X_test, y_train, y_test)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtAX7E1IzzrN"
      },
      "source": [
        "# 14 CatBoost ✅(grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY2OQRki0gFz",
        "outputId": "8e1aaf3e-2b69-458c-d58d-0f83acfe2263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n",
            "{'class_weights': [1, 2], 'depth': 4, 'iterations': 200, 'l2_leaf_reg': 1, 'learning_rate': 0.01}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.76      0.82       796\n",
            "           1       0.56      0.75      0.64       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.72      0.75      0.73      1125\n",
            "weighted avg       0.79      0.76      0.76      1125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "!pip install catboost\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def model14(X_train, X_test, y_train, y_test):\n",
        "    model = CatBoostClassifier(random_seed=42, verbose=0)\n",
        "\n",
        "    param_grid = {\n",
        "        'iterations': [100, 200],\n",
        "        'learning_rate': [0.01, 0.1],\n",
        "        'depth': [4, 6],\n",
        "        'l2_leaf_reg': [1, 3],\n",
        "        'class_weights': [[1, 1], [1, 2], [1, 3], [1,4], [1,5]] # Example class weights\n",
        "    }\n",
        "    grid_search = GridSearchCV(model, param_grid, scoring='f1', cv=3, n_jobs=-1) # Use 3-fold to speed up\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    print(grid_search.best_params_)\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "    y_train_proba = best_model.predict_proba(X_train)[:, 1]\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    #print(best_model)\n",
        "    return (y_train_proba, y_pred_proba)\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model14(X_train, X_test, y_train, y_test)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVIB9X0Gz0pW"
      },
      "source": [
        "# 15 TabNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJSNVQN306tQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#!pip install pytorch-tabnet\n",
        "\n",
        "import torch\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "# Define the parameter grid for TabNet\n",
        "\n",
        "\n",
        "def model15(X_train, X_test, y_train, y_test):\n",
        "    param_grid = {\n",
        "        'n_d': [8, 16],\n",
        "        'n_a': [8, 16],\n",
        "        'n_steps': [3, 5],\n",
        "        'gamma': [1.3, 1.5],\n",
        "        'n_independent': [1,2],\n",
        "        'lambda_sparse': [1e-3, 1e-4],\n",
        "        'optimizer_fn': [torch.optim.Adam],\n",
        "        'optimizer_params': [dict(lr=2e-2)],\n",
        "        'mask_type': ['entmax'],\n",
        "        'scheduler_params': [dict(mode=\"min\", patience=5, min_lr=1e-5, factor=0.9)],\n",
        "        'scheduler_fn': [torch.optim.lr_scheduler.ReduceLROnPlateau],\n",
        "        'verbose': [10]\n",
        "    }\n",
        "    tabnet_model = TabNetClassifier()\n",
        "    f1_scorer = make_scorer(f1_score, average='weighted')\n",
        "    grid_search = GridSearchCV(estimator=tabnet_model, param_grid=param_grid, scoring=f1_scorer, cv=3, n_jobs=-1, verbose=1)\n",
        "    #sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
        "\n",
        "    grid_search.fit(X_train.values, y_train.values, eval_set=[(X_test.values, y_test.values)], eval_metric=['f1'])\n",
        "\n",
        "    best_tabnet_model = grid_search.best_estimator_\n",
        "    y_pred = best_tabnet_model.predict(X_test.values)\n",
        "    y_pred_proba = best_tabnet_model.predict_proba(X_test.values)[:,1]\n",
        "\n",
        "    print(\"Classification Report for TabNet:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    y_pred_thresh = (y_pred_proba >= best_threshold).astype(int)\n",
        "\n",
        "    print(classification_report(y_test, y_pred_thresh))\n",
        "\n",
        "    print(best_tabnet_model)\n",
        "    return y_pred_proba - best_threshold\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model15(X_train, X_test, y_train, y_test)\n",
        "    break # Remove to run for all folds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaeesu84z3u7"
      },
      "source": [
        "# 16 Node2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLrOvZun1h_e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "!pip install node2vec\n",
        "\n",
        "import networkx as nx\n",
        "from node2vec import Node2Vec\n",
        "\n",
        "def create_graph_from_dataframe(df):\n",
        "    graph = nx.Graph()\n",
        "    for index, row in df.iterrows():\n",
        "      graph.add_node(index, features=row.to_dict()) # or use a subset of columns\n",
        "    for i in range(len(df)):\n",
        "        for j in range(i + 1, len(df)):\n",
        "            similarity = np.dot(df.iloc[i], df.iloc[j])/(np.linalg.norm(df.iloc[i])*np.linalg.norm(df.iloc[j]))\n",
        "            if similarity > 0.5: # Example threshold\n",
        "                graph.add_edge(i, j, weight=similarity)\n",
        "    return graph\n",
        "\n",
        "def get_node2vec_embeddings(graph, dimensions=64, walk_length=30, num_walks=200, workers=4):\n",
        "  node2vec = Node2Vec(graph, dimensions=dimensions, walk_length=walk_length, num_walks=num_walks, workers=workers)\n",
        "  model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
        "  embeddings = {node: model.wv[str(node)] for node in graph.nodes()}\n",
        "  return embeddings\n",
        "\n",
        "def model16(X_train, X_test, y_train, y_test):\n",
        "    train_graph = create_graph_from_dataframe(X_train)\n",
        "    embeddings_train = get_node2vec_embeddings(train_graph)\n",
        "    X_train_embeddings = np.array([embeddings_train[i] for i in range(len(X_train))])\n",
        "\n",
        "\n",
        "    test_graph = create_graph_from_dataframe(X_test)\n",
        "    embeddings_test = get_node2vec_embeddings(test_graph)\n",
        "    X_test_embeddings = np.array([embeddings_test[i] for i in range(len(X_test))])\n",
        "\n",
        "\n",
        "    param_grid = {\n",
        "        'class_weight': [None, 'balanced', {0:1, 1:10}],\n",
        "        # ... other hyperparameters for your classifier\n",
        "    }\n",
        "\n",
        "    # Example classifier: Logistic Regression\n",
        "    clf = LogisticRegression()\n",
        "\n",
        "    grid_search = GridSearchCV(clf, param_grid, scoring='f1', cv=3)  # Use 3-fold for speed\n",
        "\n",
        "    grid_search.fit(X_train_embeddings, y_train)\n",
        "    best_clf = grid_search.best_estimator_\n",
        "    y_pred = best_clf.predict(X_test_embeddings)\n",
        "    y_pred_proba = best_clf.predict_proba(X_test_embeddings)[:, 1]\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    y_pred_thresh = (y_pred_proba >= best_threshold).astype(int)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(best_clf)\n",
        "    return y_pred_proba - best_threshold\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model16(X_train, X_test, y_train, y_test)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AsbpV6iz1Ci"
      },
      "source": [
        "# 17 NGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBU9IFAa1al-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "!pip install ngboost\n",
        "from ngboost import NGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "def model17(X_train, X_test, y_train, y_test):\n",
        "    param_grid = {\n",
        "        'Dist': ['Normal', 'LogNormal'],\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.1],\n",
        "        'minibatch_frac': [0.5, 1.0],\n",
        "        'natural_gradient': [True, False],\n",
        "        'verbose': [False],\n",
        "        'Base': [DecisionTreeClassifier(max_depth=3)] # Example base learner, you can experiment\n",
        "    }\n",
        "    ngb_model = NGBClassifier()\n",
        "    grid_search = GridSearchCV(estimator=ngb_model, param_grid=param_grid, scoring='f1', cv=3, n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_ngb_model = grid_search.best_estimator_\n",
        "    y_pred_proba = best_ngb_model.predict_proba(X_test)[:, 1]\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(best_ngb_model)\n",
        "\n",
        "    return y_pred_proba - best_threshold\n",
        "\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "  model17(X_train, X_test, y_train, y_test)\n",
        "  break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaePttkvz1md"
      },
      "source": [
        "# 18 DeepFM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gZxPjvr2RdI"
      },
      "outputs": [],
      "source": [
        "# prompt: use DeepFM and grid search (including but not limited to class weight) to predict y_test and maximize f1\n",
        "\n",
        "!pip install deepctr\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from deepctr.models import DeepFM\n",
        "from deepctr.feature_column import SparseFeat, DenseFeat, get_feature_names\n",
        "\n",
        "# Assuming your data is preprocessed as in the previous example\n",
        "# ... (Your existing code for data loading and preprocessing)\n",
        "\n",
        "# Create feature columns\n",
        "sparse_features = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService',\n",
        "                   'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
        "                   'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
        "dense_features = ['tenure', 'MonthlyCharges', 'TotalCharges', 'num_services', 'revenue_proxy',\n",
        "                  'contract_tenure', 'tenure_squared', 'tenure_cubed', 'is_MTM', 'high_charge',\n",
        "                  'MTM_high_charge', 'log_TotalCharges', 'log_tenure', 'log_MonthlyCharges',\n",
        "                  'log_num_services', 'log_revenue_proxy', 'log_contract_tenure',\n",
        "                  'log_MTM_high_charge', 'log_age']\n",
        "\n",
        "\n",
        "for feat in sparse_features:\n",
        "    lbe = LabelEncoder()\n",
        "    X[feat] = lbe.fit_transform(X[feat])\n",
        "mms = MinMaxScaler(feature_range=(0,1))\n",
        "X[dense_features] = mms.fit_transform(X[dense_features])\n",
        "\n",
        "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=X[feat].nunique(),embedding_dim=4)\n",
        "                        for i,feat in enumerate(sparse_features)] + [DenseFeat(feat, 1,)\n",
        "                        for feat in dense_features]\n",
        "\n",
        "dnn_feature_columns = fixlen_feature_columns\n",
        "linear_feature_columns = fixlen_feature_columns\n",
        "\n",
        "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'dnn_hidden_units': [(128, 64), (256, 128)],\n",
        "    'l2_reg_linear': [0.001, 0.01],\n",
        "    'l2_reg_embedding': [0.001, 0.01],\n",
        "    'l2_reg_dnn': [0, 0.001],\n",
        "    'dnn_dropout': [0, 0.1],\n",
        "    'class_weight': [{0:1, 1:1.5}, {0:1, 1:2}, 'balanced']\n",
        "}\n",
        "\n",
        "# Initialize DeepFM model\n",
        "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary')\n",
        "\n",
        "# Perform GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "grid_search = GridSearchCV(model, param_grid, scoring='f1', cv=3, n_jobs=-1, verbose=1) # Use 3-fold for speed\n",
        "grid_search.fit(X_train[feature_names], y_train, )\n",
        "\n",
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_proba = best_model.predict(X_test[feature_names], batch_size=256)\n",
        "\n",
        "# Find the best threshold for maximizing F1-score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "best_threshold = thresholds[best_threshold_index]\n",
        "\n",
        "y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcMQiU-uz1_G"
      },
      "source": [
        "# 19 RuleFit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vz-z8TNz8124"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "!pip install rulefit\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from rulefit import RuleFit\n",
        "\n",
        "def model19(X_train, X_test, y_train, y_test):\n",
        "    # Define the parameter grid for RuleFit\n",
        "    param_grid = {\n",
        "        'max_rules': [50, 100],  # Maximum number of rules to generate\n",
        "        'tree_size': [2, 4],      # Maximum size of each rule tree\n",
        "        'sample_fract': [0.7, 0.9], # Fraction of samples to use for rule generation\n",
        "        'memory_par': [0.01, 0.05], # Memory parameter for rule generation\n",
        "        'exp_rand_tree_size': [True, False], # Use randomized tree sizes\n",
        "        'class_weight': ['balanced', None],\n",
        "    }\n",
        "\n",
        "    # Initialize RuleFit\n",
        "    rulefit_model = RuleFit()\n",
        "\n",
        "    # Perform GridSearchCV\n",
        "    grid_search = GridSearchCV(estimator=rulefit_model, param_grid=param_grid, scoring='f1', cv=3, n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best model\n",
        "    best_rulefit_model = grid_search.best_estimator_\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred_proba = best_rulefit_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Find the best threshold for maximizing F1-score\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "\n",
        "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(best_rulefit_model)\n",
        "    return y_pred_proba - best_threshold\n",
        "\n",
        "\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model19(X_train, X_test, y_train, y_test)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYSnDxJMz2bW"
      },
      "source": [
        "# 20 VIME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDOU22kl9YOC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "!pip install VIME\n",
        "\n",
        "import VIME\n",
        "\n",
        "def model20(X_train, X_test, y_train, y_test):\n",
        "    # Initialize VIME model\n",
        "    vime_model = VIME.VIME()\n",
        "\n",
        "    # Define parameter grid for GridSearchCV (adjust as needed)\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100],  # Example values, adjust based on your data\n",
        "        'learning_rate': [0.01, 0.1],  # Example values\n",
        "        'max_depth': [3, 5],  # Example values\n",
        "        'class_weight': [None, 'balanced'] # Include class_weight\n",
        "    }\n",
        "\n",
        "    # Use GridSearchCV to find optimal hyperparameters\n",
        "    grid_search = GridSearchCV(vime_model, param_grid, scoring='f1', cv=3, n_jobs=-1)  # Use 3-fold for speed\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_vime_model = grid_search.best_estimator_\n",
        "    y_pred_proba = best_vime_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(best_vime_model)\n",
        "    return y_pred_proba - best_threshold\n",
        "\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model20(X_train, X_test, y_train, y_test)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gac7TSQkz24Q"
      },
      "source": [
        "# 21 Logistic Regression with Polynomial Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNjieBvh98AZ"
      },
      "outputs": [],
      "source": [
        "# prompt: use logistic regression with polynomial features and grid search (including but not limited to class weight) to predict y_test and maximize f1\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create polynomial features\n",
        "poly = PolynomialFeatures(degree=2) # Example degree, adjust as needed\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# Define the parameter grid for Logistic Regression with polynomial features\n",
        "param_grid = {\n",
        "    'logisticregression__C': [0.1, 1, 10],  # Regularization parameter\n",
        "    'logisticregression__class_weight': [None, 'balanced'], # Class weights\n",
        "    'logisticregression__solver': ['liblinear', 'saga'], # Solvers\n",
        "    'logisticregression__penalty': ['l1', 'l2'] # Penalty\n",
        "}\n",
        "\n",
        "# Create a pipeline with polynomial features and Logistic Regression\n",
        "log_reg_poly = make_pipeline(StandardScaler(), PolynomialFeatures(degree=2), LogisticRegression(max_iter=1000))\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search_poly = GridSearchCV(log_reg_poly, param_grid, scoring='f1', cv=5) # Use 5-fold cross-validation\n",
        "grid_search_poly.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Get the best model\n",
        "best_log_reg_poly = grid_search_poly.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_proba = best_log_reg_poly.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Find the best threshold for maximizing F1-score\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
        "best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "best_threshold = thresholds[best_threshold_index]\n",
        "\n",
        "y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "print(classification_report(y_test, y_pred))\n",
        "best_log_reg_poly\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsBMYYwCz3WE"
      },
      "source": [
        "# 22 Factorization Machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OT5ATQ0d-Cq8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "!pip install pyfm\n",
        "\n",
        "from pyfm import pylibfm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "\n",
        "def model22(X_train, X_test, y_train, y_test):\n",
        "    # Convert pandas DataFrames to numpy arrays\n",
        "    X_train = X_train.values\n",
        "    X_test = X_test.values\n",
        "    y_train = y_train.values\n",
        "    y_test = y_test.values\n",
        "\n",
        "    # Define the parameter grid for Factorization Machines\n",
        "    param_grid = {\n",
        "        'num_factors': [8, 16, 32],\n",
        "        'num_iterations': [50, 100],\n",
        "        'learning_rate': [0.01, 0.1],\n",
        "        'regularization': [0.01, 0.1],\n",
        "        'class_weight': [{0:1, 1:1.5}, {0:1, 1:2}, 'balanced'] # Include class_weight\n",
        "        }\n",
        "\n",
        "    # Initialize Factorization Machines model\n",
        "    fm = pylibfm.FM()\n",
        "    f1_scorer = make_scorer(f1_score, average='weighted')\n",
        "\n",
        "    # Perform GridSearchCV\n",
        "    grid_search = GridSearchCV(fm, param_grid, scoring=f1_scorer, cv=3, n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best model\n",
        "    best_fm_model = grid_search.best_estimator_\n",
        "\n",
        "    # Predict probabilities on the test set\n",
        "    y_pred_proba = best_fm_model.predict(X_test)\n",
        "\n",
        "    # Find the best threshold for maximizing F1-score\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "\n",
        "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(best_fm_model)\n",
        "    return y_pred_proba - best_threshold\n",
        "\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model22(X_train, X_test, y_train, y_test)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDaHy2BCxyKi"
      },
      "source": [
        "# Meta Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9B7Mj2DMDGOc"
      },
      "outputs": [],
      "source": [
        "# Scikit-learn classifiers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# 1) Logistic Regression\n",
        "model1 = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, class_weight = 'balanced', solver = 'saga', penalty = 'l1', C = 0.5))\n",
        "# 2) Decision Tree\n",
        "#model2 = DecisionTreeClassifier(random_state=42)\n",
        "# 3) Random Forest\n",
        "model3 = RandomForestClassifier(random_state=42)\n",
        "# 4) Gradient Boosting (scikit-learn)\n",
        "model4 = GradientBoostingClassifier(random_state=42)\n",
        "# 5) Gaussian Naive Bayes\n",
        "model5 = GaussianNB()\n",
        "# 6) KNeighbors\n",
        "model6 = KNeighborsClassifier()\n",
        "# 7) SVM\n",
        "model7 = SVC(probability=True, random_state=42)\n",
        "# 8) XGBoost\n",
        "model8 = XGBClassifier(eval_metric='logloss', random_state=42)\n",
        "# 9) Extra Trees\n",
        "model9 = ExtraTreesClassifier(random_state=42)\n",
        "# 10) Multi-Layer Perceptron\n",
        "model10 = MLPClassifier(max_iter=300, random_state=42)\n",
        "# light gbm\n",
        "#multinomial nb\n",
        "#bernouli nb\n",
        "\n",
        "# Put them in a list for convenience\n",
        "models = [\n",
        "    (\"LogisticRegression\", model1),\n",
        "    #(\"DecisionTree\", model2),\n",
        "    #(\"RandomForest\", model3),\n",
        "    #(\"GradientBoosting\", model4),\n",
        "    (\"NaiveBayes\", model5),\n",
        "    #(\"KNN\", model6),\n",
        "    #(\"SVM\", model7),\n",
        "    #(\"XGB\", model8),\n",
        "    #(\"ExtraTrees\", model9),\n",
        "    (\"MLP\", model10)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBoknfBxy6m_"
      },
      "outputs": [],
      "source": [
        "# prompt: see which features impact churn the most\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'X_train' and 'model1' (Logistic Regression) are defined from the previous code\n",
        "\n",
        "# Fit the model (if not already fitted)\n",
        "for model in models:\n",
        "  model = model[1]\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # Get feature importances\n",
        "  feature_importances = model.coef_[0]\n",
        "\n",
        "  # Create a DataFrame for easier handling\n",
        "  feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
        "\n",
        "  # Sort by absolute importance (to see both positive and negative impacts)\n",
        "  feature_importance_df = feature_importance_df.reindex(feature_importance_df['Importance'].abs().sort_values(ascending=False).index)\n",
        "\n",
        "  # Plot the feature importances\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
        "  plt.title('Feature Importance (Logistic Regression)')\n",
        "  plt.xlabel('Importance')\n",
        "  plt.ylabel('Feature')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCdxGRKi18M1"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "feat_imp_rf = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
        "feat_imp_rf = feat_imp_rf.sort_values(ascending=False)\n",
        "\n",
        "print(\"Top 10 RandomForest features:\")\n",
        "print(feat_imp_rf.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fIH5yi6oTv8"
      },
      "source": [
        "# Meta Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyRq79bHDHeE"
      },
      "outputs": [],
      "source": [
        "train_preds = []\n",
        "for name, m in models:\n",
        "    train_preds.append(m.predict_proba(X_train)[:, 1])\n",
        "\n",
        "meta_X_train = pd.DataFrame(np.column_stack(train_preds), columns=[n for n,_ in models])\n",
        "meta_y_train = y_train\n",
        "\n",
        "meta_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "meta_model.fit(meta_X_train, meta_y_train)\n",
        "print(\"\\nMeta-model has been trained on stacked predictions of the 10 base models.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cUBhG5kDMDP"
      },
      "outputs": [],
      "source": [
        "# Combine base models' test predictions\n",
        "test_preds = []\n",
        "for name, m in models:\n",
        "    predictions_test = m.predict_proba(X_test)[:, 1]\n",
        "    test_preds.append(predictions_test)\n",
        "\n",
        "meta_X_test = pd.DataFrame(np.column_stack(test_preds), columns=[n for n,_ in models])\n",
        "\n",
        "# Predict using the meta-model\n",
        "meta_test_pred = meta_model.predict(meta_X_test)\n",
        "meta_test_prob = meta_model.predict_proba(meta_X_test)[:, 1]\n",
        "\n",
        "# Evaluate the final stacked model\n",
        "print(\"\\n***** Evaluation of the final (stacked) meta-model *****\")\n",
        "print(classification_report(y_test, meta_test_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOemoNMO5EW1"
      },
      "outputs": [],
      "source": [
        "models = [('1',model1), ('2', model2), ('3', model3), ('4', model4), ('5', model5), ('8', model8), ('9', model9), ('14', model14)]#, ('14', model14)]\n",
        "def stack_models(X_train, X_test, y_train, y_test, models):\n",
        "    X_train2 = X_train.copy()\n",
        "    X_test2 = X_test.copy()\n",
        "\n",
        "    for name, model in models:\n",
        "        X_train2[name], X_test2[name] = model(X_train, X_test, y_train, y_test)\n",
        "    for name, model in models:\n",
        "        X_train2['final'+name], X_test2['final'+name] = model(X_train2, X_test2, y_train, y_test)\n",
        "\n",
        "    return X_train2, X_test2, y_train, y_test\n",
        "\n",
        "\n",
        "def evalulate(X_train2, X_test2, y_train, y_test):\n",
        "\n",
        "    meta_model = LogisticRegression(max_iter=1000, class_weight='balanced',random_state=42, solver = 'saga', penalty = 'l1')\n",
        "    #meta_model = XGBClassifier(eval_metric='logloss', random_state=42)\n",
        "    #meta_model = RandomForestClassifier(random_state=42)\n",
        "    #meta_model = GradientBoostingClassifier(random_state=42)\n",
        "    meta_model.fit(X_train2, y_train)\n",
        "    meta_test_pred = meta_model.predict(X_test2)\n",
        "\n",
        "    print(\"\\n***** Evaluation of the final (stacked) meta-model *****\")\n",
        "    print(classification_report(y_test, meta_test_pred))\n",
        "    print(meta_model.coef_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufgqe-2k5lke",
        "outputId": "67a0c3ec-9516-4540-ec46-bc9c2691a2eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.69      0.79       796\n",
            "           1       0.53      0.84      0.65       329\n",
            "\n",
            "    accuracy                           0.73      1125\n",
            "   macro avg       0.72      0.76      0.72      1125\n",
            "weighted avg       0.80      0.73      0.75      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.72      0.79       796\n",
            "           1       0.52      0.74      0.61       329\n",
            "\n",
            "    accuracy                           0.73      1125\n",
            "   macro avg       0.70      0.73      0.70      1125\n",
            "weighted avg       0.77      0.73      0.74      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.76      0.81       796\n",
            "           1       0.56      0.76      0.64       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.72      0.76      0.73      1125\n",
            "weighted avg       0.79      0.76      0.76      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.73      0.81       796\n",
            "           1       0.55      0.78      0.64       329\n",
            "\n",
            "    accuracy                           0.75      1125\n",
            "   macro avg       0.72      0.76      0.73      1125\n",
            "weighted avg       0.79      0.75      0.76      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83       796\n",
            "           1       0.59      0.60      0.60       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.71      0.72      0.71      1125\n",
            "weighted avg       0.76      0.76      0.76      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.70      0.79       796\n",
            "           1       0.52      0.80      0.63       329\n",
            "\n",
            "    accuracy                           0.73      1125\n",
            "   macro avg       0.71      0.75      0.71      1125\n",
            "weighted avg       0.79      0.73      0.74      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.72      0.80       796\n",
            "           1       0.54      0.82      0.65       329\n",
            "\n",
            "    accuracy                           0.75      1125\n",
            "   macro avg       0.72      0.77      0.73      1125\n",
            "weighted avg       0.80      0.75      0.76      1125\n",
            "\n",
            "{'class_weights': [1, 2], 'depth': 4, 'iterations': 200, 'l2_leaf_reg': 1, 'learning_rate': 0.01}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.76      0.82       796\n",
            "           1       0.56      0.75      0.64       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.72      0.75      0.73      1125\n",
            "weighted avg       0.79      0.76      0.76      1125\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-3266553412>:30: RuntimeWarning: invalid value encountered in divide\n",
            "  f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83       796\n",
            "           1       0.00      0.00      0.00       329\n",
            "\n",
            "    accuracy                           0.71      1125\n",
            "   macro avg       0.35      0.50      0.41      1125\n",
            "weighted avg       0.50      0.71      0.59      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84       796\n",
            "           1       0.61      0.54      0.57       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.71      0.70      0.71      1125\n",
            "weighted avg       0.76      0.76      0.76      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.87      0.84       796\n",
            "           1       0.61      0.51      0.56       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.71      0.69      0.70      1125\n",
            "weighted avg       0.75      0.76      0.76      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84       796\n",
            "           1       0.61      0.54      0.57       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.71      0.70      0.71      1125\n",
            "weighted avg       0.76      0.76      0.76      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.78      0.81       796\n",
            "           1       0.56      0.66      0.61       329\n",
            "\n",
            "    accuracy                           0.75      1125\n",
            "   macro avg       0.70      0.72      0.71      1125\n",
            "weighted avg       0.76      0.75      0.75      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83       796\n",
            "           1       0.59      0.56      0.58       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.71      0.70      0.70      1125\n",
            "weighted avg       0.76      0.76      0.76      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.83      0.83       796\n",
            "           1       0.59      0.61      0.60       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.72      0.72      0.72      1125\n",
            "weighted avg       0.77      0.76      0.76      1125\n",
            "\n",
            "{'class_weights': [1, 3], 'depth': 4, 'iterations': 100, 'l2_leaf_reg': 3, 'learning_rate': 0.01}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.80      0.82       796\n",
            "           1       0.57      0.65      0.61       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.71      0.73      0.72      1125\n",
            "weighted avg       0.77      0.76      0.76      1125\n",
            "\n",
            "\n",
            "***** Evaluation of the final (stacked) meta-model *****\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.59      0.71       796\n",
            "           1       0.46      0.84      0.59       329\n",
            "\n",
            "    accuracy                           0.66      1125\n",
            "   macro avg       0.68      0.72      0.65      1125\n",
            "weighted avg       0.77      0.66      0.68      1125\n",
            "\n",
            "[[ 1.15492047e-06  1.82555200e-06  1.92125460e-09 -1.06757559e-06\n",
            "  -3.33342462e-05  2.27779841e-06  2.10236711e-06  9.24019193e-06\n",
            "  -1.18739910e-06  5.75104830e-08  4.98856896e-07 -1.01121016e-06\n",
            "   2.00830183e-06  2.05132863e-06 -3.31913586e-05  4.26120196e-06\n",
            "   5.69085962e-06  3.19582300e-04  2.65690601e-04  2.43172627e-06\n",
            "   2.78354758e-04 -1.16997039e-03 -9.11129189e-04  1.46466623e-06\n",
            "   0.00000000e+00  3.85222227e-06  0.00000000e+00  1.17102798e-05\n",
            "  -5.98811603e-07  1.44656731e-05  1.89550143e-06  1.17180598e-05\n",
            "  -4.79594582e-06  0.00000000e+00  1.26097661e-06  2.92101055e-06\n",
            "   4.51333507e-06  5.16515862e-06  1.62113891e-05  1.72230665e-06\n",
            "   5.95224075e-06  6.37995919e-06  4.02311794e-06  9.71390375e-06\n",
            "   1.49957019e-05  1.44249724e-05  2.54885186e-05  1.87676166e-06\n",
            "   9.75510040e-06  1.49944152e-05  1.46352715e-05]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "for i, (X_train, X_test, y_train, y_test) in enumerate(datasets):\n",
        "    X_train2, X_test2, y_train2, y_test2 = stack_models(X_train, X_test, y_train, y_test, models)\n",
        "    evalulate(X_train2, X_test2, y_train2, y_test2)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Levi\\AppData\\Local\\Temp\\ipykernel_39004\\346441436.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['TotalCharges'].fillna(median_tc, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"train_data.csv\")\n",
        "if 'customerID' in df.columns:\n",
        "    df.drop('customerID', axis=1, inplace=True)\n",
        "if 'TotalCharges' in df.columns:\n",
        "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "median_tc = df['TotalCharges'].median()\n",
        "df['TotalCharges'].fillna(median_tc, inplace=True)\n",
        "df['Contract'] = df['Contract'].map({'Month-to-month': 2, 'One year': 12, 'Two year': 24})\n",
        "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
        "df['Partner'] = df['Partner'].map({'Yes': 1, 'No': 0})\n",
        "df['Dependents'] = df['Dependents'].map({'Yes': 1, 'No': 0})\n",
        "df['PhoneService'] = df['PhoneService'].map({'Yes': 1, 'No': 0})\n",
        "df['MultipleLines'] = df['MultipleLines'].map({'Yes': 1, 'No': 0, 'No phone service': 0})\n",
        "df['OnlineSecurity'] = df['OnlineSecurity'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['OnlineBackup'] = df['OnlineBackup'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['DeviceProtection'] = df['DeviceProtection'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['TechSupport'] = df['TechSupport'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['StreamingTV'] = df['StreamingTV'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['StreamingMovies'] = df['StreamingMovies'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['PaperlessBilling'] = df['PaperlessBilling'].map({'Yes': 1, 'No': 0})\n",
        "df['gender'] = df['gender'].map({'Male': 1, 'Female': 0})\n",
        "df['PaymentMethod'] = df['PaymentMethod'].map({'Electronic check': 2, 'Mailed check': 1, 'Bank transfer (automatic)': 4, 'Credit card (automatic)': 3})\n",
        "df['InternetService'] = df['InternetService'].map({'Fiber optic': 2, 'DSL': 1, 'No':0})\n",
        "df['Month'] = df['TotalCharges']/ df['MonthlyCharges']\n",
        "\n",
        "services = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
        "            'StreamingTV', 'StreamingMovies']\n",
        "df['num_services'] = df[services].sum(axis=1)\n",
        "df['revenue_proxy'] = df['MonthlyCharges'] * df['tenure']\n",
        "df['contract_tenure'] = df['Contract'] * df['tenure']\n",
        "df['tenure_squared'] = df['tenure'] ** 2\n",
        "df['tenure_cubed'] = df['tenure'] ** 3\n",
        "df['is_MTM'] = (df['Contract'] == 3).astype(int) # Assuming 3 represents Month-to-month\n",
        "df['high_charge'] = (df['MonthlyCharges'] > df['MonthlyCharges'].mean()).astype(int)\n",
        "df['MTM_high_charge'] = df['is_MTM'] * df['high_charge']\n",
        "df['log_TotalCharges'] = np.log1p(df['TotalCharges'])\n",
        "df['log_tenure'] = np.log1p(df['tenure'])\n",
        "df['log_MonthlyCharges'] = np.log1p(df['MonthlyCharges'])\n",
        "df['log_num_services'] = np.log1p(df['num_services'])\n",
        "df['log_revenue_proxy'] = np.log1p(df['revenue_proxy'])\n",
        "df['log_contract_tenure'] = np.log1p(df['contract_tenure'])\n",
        "df['log_MTM_high_charge'] = np.log1p(df['MTM_high_charge'])\n",
        "df['log_age'] = np.log1p(df['SeniorCitizen'])\n",
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "datasets = create_kfold_datasets(X, y, n_splits=5, random_state=42)\n",
        "predictions_test = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Levi\\AppData\\Local\\Temp\\ipykernel_39004\\1028302584.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['TotalCharges'].fillna(median_tc, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"test_data.csv\")\n",
        "customerID = df['customerID']\n",
        "if 'customerID' in df.columns:\n",
        "    df.drop('customerID', axis=1, inplace=True)\n",
        "if 'TotalCharges' in df.columns:\n",
        "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "median_tc = df['TotalCharges'].median()\n",
        "df['TotalCharges'].fillna(median_tc, inplace=True)\n",
        "df['Contract'] = df['Contract'].map({'Month-to-month': 2, 'One year': 12, 'Two year': 24})\n",
        "df['Partner'] = df['Partner'].map({'Yes': 1, 'No': 0})\n",
        "df['Dependents'] = df['Dependents'].map({'Yes': 1, 'No': 0})\n",
        "df['PhoneService'] = df['PhoneService'].map({'Yes': 1, 'No': 0})\n",
        "df['MultipleLines'] = df['MultipleLines'].map({'Yes': 1, 'No': 0, 'No phone service': 0})\n",
        "df['OnlineSecurity'] = df['OnlineSecurity'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['OnlineBackup'] = df['OnlineBackup'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['DeviceProtection'] = df['DeviceProtection'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['TechSupport'] = df['TechSupport'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['StreamingTV'] = df['StreamingTV'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['StreamingMovies'] = df['StreamingMovies'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['PaperlessBilling'] = df['PaperlessBilling'].map({'Yes': 1, 'No': 0})\n",
        "df['gender'] = df['gender'].map({'Male': 1, 'Female': 0})\n",
        "df['PaymentMethod'] = df['PaymentMethod'].map({'Electronic check': 2, 'Mailed check': 1, 'Bank transfer (automatic)': 4, 'Credit card (automatic)': 3})\n",
        "df['InternetService'] = df['InternetService'].map({'Fiber optic': 2, 'DSL': 1, 'No':0})\n",
        "df['Month'] = df['TotalCharges']/ df['MonthlyCharges']\n",
        "services = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
        "            'StreamingTV', 'StreamingMovies']\n",
        "df['num_services'] = df[services].sum(axis=1)\n",
        "df['revenue_proxy'] = df['MonthlyCharges'] * df['tenure']\n",
        "df['contract_tenure'] = df['Contract'] * df['tenure']\n",
        "df['tenure_squared'] = df['tenure'] ** 2\n",
        "df['tenure_cubed'] = df['tenure'] ** 3\n",
        "df['is_MTM'] = (df['Contract'] == 3).astype(int) # Assuming 3 represents Month-to-month\n",
        "df['high_charge'] = (df['MonthlyCharges'] > df['MonthlyCharges'].mean()).astype(int)\n",
        "df['MTM_high_charge'] = df['is_MTM'] * df['high_charge']\n",
        "df['log_TotalCharges'] = np.log1p(df['TotalCharges'])\n",
        "df['log_tenure'] = np.log1p(df['tenure'])\n",
        "df['log_MonthlyCharges'] = np.log1p(df['MonthlyCharges'])\n",
        "df['log_num_services'] = np.log1p(df['num_services'])\n",
        "df['log_revenue_proxy'] = np.log1p(df['revenue_proxy'])\n",
        "df['log_contract_tenure'] = np.log1p(df['contract_tenure'])\n",
        "df['log_MTM_high_charge'] = np.log1p(df['MTM_high_charge'])\n",
        "df['log_age'] = np.log1p(df['SeniorCitizen'])\n",
        "X_sub = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best threshold: 0.2579 with F1 score: 0.6166\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.79      0.83      3714\n",
            "           1       0.55      0.70      0.62      1357\n",
            "\n",
            "    accuracy                           0.77      5071\n",
            "   macro avg       0.71      0.75      0.72      5071\n",
            "weighted avg       0.79      0.77      0.77      5071\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([0.07876278, 0.42096   , 0.51907048, 0.00223104, 0.10675937,\n",
              "        0.03104483, 0.27424938, 0.12337883, 0.25340572, 0.12774865,\n",
              "        0.00197445, 0.04845579, 0.037478  , 0.56069715, 0.55257881,\n",
              "        0.43819058, 0.12182648, 0.05509149, 0.32957928, 0.35766896,\n",
              "        0.01618156, 0.32671372, 0.02720504, 0.54446659, 0.00294923,\n",
              "        0.53152446, 0.00305484, 0.40054787, 0.27722788, 0.37659372,\n",
              "        0.03845343, 0.45667093, 0.31580079, 0.28928241, 0.16987928,\n",
              "        0.33420911, 0.0871548 , 0.4241233 , 0.30580577, 0.07502064,\n",
              "        0.19181932, 0.35014987, 0.39893156, 0.00702851, 0.01733895,\n",
              "        0.00697469, 0.49190589, 0.01642517, 0.22849334, 0.0172248 ,\n",
              "        0.23459182, 0.52684124, 0.41590318, 0.31198764, 0.3771376 ,\n",
              "        0.0492269 , 0.2326905 , 0.44624668, 0.01769607, 0.13779464,\n",
              "        0.00214921, 0.00459907, 0.01007342, 0.02192229, 0.09495731,\n",
              "        0.18867562, 0.03073605, 0.02821222, 0.51276047, 0.17192025,\n",
              "        0.32166102, 0.0018736 , 0.17762695, 0.13263641, 0.03565359,\n",
              "        0.09624305, 0.0801475 , 0.05899136, 0.03225225, 0.48923092,\n",
              "        0.00568751, 0.34117698, 0.10118734, 0.17983064, 0.02415279,\n",
              "        0.05858557, 0.14061689, 0.07620658, 0.04445568, 0.01507318,\n",
              "        0.25958915, 0.31364255, 0.47159568, 0.1477032 , 0.03097064,\n",
              "        0.13876814, 0.01806735, 0.02542772, 0.10515873, 0.3751036 ,\n",
              "        0.12387864, 0.00875933, 0.01016825, 0.10078125, 0.03404373,\n",
              "        0.29505337, 0.09777926, 0.53958639, 0.47255332, 0.08162132,\n",
              "        0.00265691, 0.03742207, 0.01974337, 0.18865003, 0.38603748,\n",
              "        0.5225129 , 0.26954991, 0.01042112, 0.03532447, 0.20297512,\n",
              "        0.33390143, 0.07512389, 0.07616521, 0.464664  , 0.39117603,\n",
              "        0.33742477, 0.00425942, 0.00786711, 0.00243428, 0.03700956,\n",
              "        0.1440508 , 0.01547585, 0.01764313, 0.10403162, 0.01105955,\n",
              "        0.00295001, 0.4744601 , 0.00806966, 0.00426868, 0.52520868,\n",
              "        0.27968959, 0.14130239, 0.00239509, 0.42385029, 0.03327331,\n",
              "        0.05392738, 0.3567943 , 0.4428613 , 0.0981725 , 0.00899041,\n",
              "        0.5590006 , 0.26080787, 0.44720387, 0.35852579, 0.16003332,\n",
              "        0.5117671 , 0.4488913 , 0.16047097, 0.05241883, 0.50693842,\n",
              "        0.46181574, 0.38663265, 0.05136593, 0.00181569, 0.06008362,\n",
              "        0.18280203, 0.43905075, 0.15974409, 0.00372232, 0.25613276,\n",
              "        0.01127751, 0.05155436, 0.46347115, 0.56605145, 0.05853668,\n",
              "        0.00228918, 0.26634725, 0.17493433, 0.03458632, 0.02246967,\n",
              "        0.07336187, 0.51833024, 0.2762854 , 0.01109112, 0.01006764,\n",
              "        0.23808919, 0.09470267, 0.00342372, 0.39457755, 0.3461379 ,\n",
              "        0.01476221, 0.08432308, 0.41413104, 0.02805544, 0.01055866,\n",
              "        0.05436399, 0.05356751, 0.03270987, 0.23597026, 0.07526173,\n",
              "        0.00383816, 0.00745842, 0.07021197, 0.36802679, 0.29073647,\n",
              "        0.00287411, 0.01887736, 0.07690528, 0.36994373, 0.49914623,\n",
              "        0.00563403, 0.60379328, 0.00676772, 0.45864017, 0.06912855,\n",
              "        0.45818864, 0.00191626, 0.01727729, 0.2012596 , 0.02456141,\n",
              "        0.03733442, 0.0601209 , 0.06166858, 0.47265335, 0.23881266,\n",
              "        0.37569312, 0.45869967, 0.33631299, 0.0025451 , 0.18599613,\n",
              "        0.04413061, 0.1387001 , 0.09186417, 0.52374265, 0.33609804,\n",
              "        0.01637217, 0.06048456, 0.372209  , 0.08309787, 0.53384395,\n",
              "        0.01006771, 0.52257739, 0.02048728, 0.4220564 , 0.00190131,\n",
              "        0.00267623, 0.32631236, 0.48539976, 0.32187018, 0.16918141,\n",
              "        0.23967863, 0.06988002, 0.01481359, 0.10815837, 0.00952453,\n",
              "        0.28798595, 0.03891093, 0.02107488, 0.03348129, 0.10315083,\n",
              "        0.00206243, 0.02005146, 0.2515424 , 0.5377963 , 0.59461298,\n",
              "        0.2275264 , 0.21506635, 0.28780463, 0.0710489 , 0.00218297,\n",
              "        0.37004541, 0.49949096, 0.03247725, 0.21544582, 0.17421809,\n",
              "        0.01869813, 0.17722146, 0.01040701, 0.04919264, 0.14813101,\n",
              "        0.15856541, 0.40485519, 0.03114339, 0.04519796, 0.25142942,\n",
              "        0.37292371, 0.39915973, 0.02220941, 0.00205366, 0.14422341,\n",
              "        0.44207409, 0.13047065, 0.05688213, 0.00328589, 0.00621921,\n",
              "        0.01609909, 0.00708964, 0.32900903, 0.47313275, 0.00399125,\n",
              "        0.07169857, 0.05539708, 0.03072901, 0.13916733, 0.00274321,\n",
              "        0.46454904, 0.02696836, 0.4307237 , 0.07674661, 0.2622627 ,\n",
              "        0.00268712, 0.17885893, 0.43573215, 0.0574735 , 0.51898922,\n",
              "        0.47963839, 0.00235572, 0.04759437, 0.00255599, 0.36036792,\n",
              "        0.04595027, 0.30626736, 0.50203767, 0.18077152, 0.32297563,\n",
              "        0.16559381, 0.00855483, 0.11527006, 0.31532981, 0.05000094,\n",
              "        0.57627678, 0.38171822, 0.34080958, 0.0081932 , 0.49226259,\n",
              "        0.14656354, 0.00267056, 0.25243606, 0.00906729, 0.59249759,\n",
              "        0.41750267, 0.25349745, 0.06222485, 0.42269958, 0.23885468,\n",
              "        0.37277284, 0.31356309, 0.01463161, 0.46728776, 0.1719702 ,\n",
              "        0.031257  , 0.44634503, 0.53649446, 0.32086595, 0.30585574,\n",
              "        0.46522628, 0.01893439, 0.10109862, 0.55914953, 0.16212926,\n",
              "        0.12132561, 0.28413601, 0.09092888, 0.00323927, 0.37577771,\n",
              "        0.00712798, 0.01497813, 0.03663597, 0.11926537, 0.00263134,\n",
              "        0.60761743, 0.27573644, 0.27009698, 0.4236402 , 0.00768628,\n",
              "        0.00172134, 0.00697907, 0.15712254, 0.56355597, 0.01848214,\n",
              "        0.28349248, 0.04441299, 0.02244738, 0.00744561, 0.17688741,\n",
              "        0.43971952, 0.1643299 , 0.0109789 , 0.18700122, 0.47911839,\n",
              "        0.36695845, 0.02973135, 0.00450298, 0.04082628, 0.05248721,\n",
              "        0.30926126, 0.41743947, 0.3471336 , 0.55865633, 0.00693033,\n",
              "        0.04916245, 0.342007  , 0.24956036, 0.14612913, 0.00213585,\n",
              "        0.03572428, 0.23844229, 0.20749579, 0.57666889, 0.32645325,\n",
              "        0.12045232, 0.00358906, 0.32904185, 0.07272489, 0.11745026,\n",
              "        0.35946687, 0.4661142 , 0.06993951, 0.0454689 , 0.49147504,\n",
              "        0.00278121, 0.0374968 , 0.37322389, 0.2156874 , 0.16567626,\n",
              "        0.55108754, 0.16128391, 0.15338216, 0.17073959, 0.21142483,\n",
              "        0.02798712, 0.47624844, 0.02762   , 0.1061063 , 0.00273949,\n",
              "        0.46088267, 0.00211155, 0.02974892, 0.09167833, 0.17205152,\n",
              "        0.08463142, 0.15327394, 0.38707388, 0.00308028, 0.04385587,\n",
              "        0.02651211, 0.16297551, 0.19944866, 0.00882726, 0.33414332,\n",
              "        0.10573699, 0.08412255, 0.23388996, 0.54175013, 0.12502415,\n",
              "        0.06865724, 0.35336048, 0.03032623, 0.02988008, 0.01423823,\n",
              "        0.03543594, 0.49052279, 0.50615089, 0.16463704, 0.05204448,\n",
              "        0.41177007, 0.30434934, 0.35827068, 0.01609758, 0.59028891,\n",
              "        0.01451464, 0.43141637, 0.00647978, 0.07582175, 0.55158615,\n",
              "        0.0956902 , 0.00916361, 0.44660305, 0.00788338, 0.26474167,\n",
              "        0.21098645, 0.03101893, 0.00971717, 0.52032734, 0.01050472,\n",
              "        0.41934404, 0.07238782, 0.02829898, 0.02088069, 0.32077817,\n",
              "        0.52214071, 0.20239613, 0.01704693, 0.05601403, 0.39657273,\n",
              "        0.55114467, 0.03167314, 0.22381848, 0.22198057, 0.1734785 ,\n",
              "        0.01030484, 0.02447262, 0.04827031, 0.00203188, 0.26112081,\n",
              "        0.00976974, 0.12859358, 0.58733507, 0.36684032, 0.02092997,\n",
              "        0.01019215, 0.16953483, 0.28901283, 0.53510856, 0.06307725,\n",
              "        0.23892418, 0.37307437, 0.49616469, 0.18465238, 0.00879154,\n",
              "        0.4024249 , 0.20099932, 0.01403347, 0.50926866, 0.59056467,\n",
              "        0.30303048, 0.01208729, 0.02327624, 0.35369798, 0.34842407,\n",
              "        0.5438105 , 0.03722839, 0.00395345, 0.00286905, 0.36785188,\n",
              "        0.03989781, 0.01108739, 0.28963339, 0.59440868, 0.02935483,\n",
              "        0.06136286, 0.03549448, 0.31846366, 0.24661746, 0.08581032,\n",
              "        0.08396107, 0.26093324, 0.03084364, 0.1199424 , 0.43612267,\n",
              "        0.0102882 , 0.01836731, 0.23757404, 0.53540693, 0.34500565,\n",
              "        0.38083572, 0.0167243 , 0.36440184, 0.32382707, 0.32373738,\n",
              "        0.07245715, 0.00249615, 0.12834092]),\n",
              " array([0.22573985, 0.2191038 , 0.52015641, ..., 0.49107279, 0.01564592,\n",
              "        0.22193257], shape=(5071,)))"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "\n",
        "\n",
        "# Train and predict using k-fold cross-validation\n",
        "def model1(X_train, X_test, y_train, y_test, X_sub):\n",
        "    log_reg = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, solver = 'saga', penalty = 'l1'))\n",
        "    log_reg2 = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, class_weight= 'balanced', solver = 'saga', penalty = 'l1'))\n",
        "    alpha = 0.8\n",
        "    beta = 0.5\n",
        "    trained_model = train_model(X_train, y_train, log_reg)\n",
        "    trained_model2 = train_model(X_train, y_train, log_reg2)\n",
        "    y_train_probs1 = trained_model.predict_proba(X_train)[:, 1]\n",
        "    y_train_probs2 = trained_model2.predict_proba(X_train)[:, 1]\n",
        "    y_train_probs = (alpha * y_train_probs1 + beta * y_train_probs2) / 2\n",
        "\n",
        "    y_probs1 = trained_model.predict_proba(X_test)[:, 1]\n",
        "    y_probs2 = trained_model2.predict_proba(X_test)[:, 1]\n",
        "    y_probs = ( alpha * y_probs1 + beta * y_probs2) / 2\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    threshold = thresholds[best_threshold_index]\n",
        "    print(f\"Best threshold: {threshold:.4f} with F1 score: {f1_scores_thresholds[best_threshold_index]:.4f}\")\n",
        "    y_pred = (y_probs >= threshold).astype(int)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    y_pred_sub = (alpha * trained_model.predict_proba(X_sub)[:, 1] + beta * trained_model2.predict_proba(X_sub)[:, 1]) / 2 >= threshold\n",
        "    submission = pd.DataFrame({'customerID': customerID, 'Churn': y_pred_sub})\n",
        "    submission['Churn'] = submission['Churn'].map({True: 'Yes', False: 'No'})\n",
        "    submission.to_csv('submission.csv', index=False)\n",
        "    print(report)\n",
        "    return (y_train_probs, y_probs)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75, random_state=42)\n",
        "model1(X_train, X_test, y_train, y_test, X_sub)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gYwSMbZ31TZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tGfm8Tsl0Pxe"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
