{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gymPOYTroHcm"
      },
      "source": [
        "# preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qNAm6YbmCuSF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "def train_model(X_train, y_train, model):\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "def predict_model(X_test, y_test, model):\n",
        "    pred_test = model.predict(X_test)\n",
        "    pred_test_proba = model.predict_proba(X_test)[:, 1]\n",
        "    predictions_test.append(pred_test_proba)\n",
        "    score = f1_score(y_test, pred_test)\n",
        "    report = classification_report(y_test, pred_test, zero_division=1)\n",
        "    return pred_test, pred_test_proba, score, report\n",
        "def create_kfold_datasets(X, y, n_splits=5, shuffle=True, random_state=None):\n",
        "    kf = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
        "    datasets = []\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "        datasets.append((X_train, X_test, y_train, y_test))\n",
        "    return datasets\n",
        "def plotit(y_test, y_probs):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
        "    plt.plot(thresholds, precision[:-1], label='Precision')\n",
        "    plt.plot(thresholds, recall[:-1], label='Recall')\n",
        "    plt.plot(thresholds, 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1]), label='F1')\n",
        "    plt.xlabel('Threshold')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Precision-Recall vs Threshold')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tuSzWSvwqpaR"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"train_data.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wP1WDondC32-"
      },
      "outputs": [],
      "source": [
        "if 'customerID' in df.columns:\n",
        "    df.drop('customerID', axis=1, inplace=True)\n",
        "if 'TotalCharges' in df.columns:\n",
        "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df.dropna(inplace=True)\n",
        "df['Contract'] = df['Contract'].map({'Month-to-month': 2, 'One year': 12, 'Two year': 24})\n",
        "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
        "df['Partner'] = df['Partner'].map({'Yes': 1, 'No': 0})\n",
        "df['Dependents'] = df['Dependents'].map({'Yes': 1, 'No': 0})\n",
        "df['PhoneService'] = df['PhoneService'].map({'Yes': 1, 'No': 0})\n",
        "df['MultipleLines'] = df['MultipleLines'].map({'Yes': 1, 'No': 0, 'No phone service': 0})\n",
        "df['OnlineSecurity'] = df['OnlineSecurity'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['OnlineBackup'] = df['OnlineBackup'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['DeviceProtection'] = df['DeviceProtection'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['TechSupport'] = df['TechSupport'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['StreamingTV'] = df['StreamingTV'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['StreamingMovies'] = df['StreamingMovies'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['PaperlessBilling'] = df['PaperlessBilling'].map({'Yes': 1, 'No': 0})\n",
        "df['gender'] = df['gender'].map({'Male': 1, 'Female': 0})\n",
        "df['PaymentMethod'] = df['PaymentMethod'].map({'Electronic check': 2, 'Mailed check': 1, 'Bank transfer (automatic)': 4, 'Credit card (automatic)': 3})\n",
        "df['InternetService'] = df['InternetService'].map({'Fiber optic': 2, 'DSL': 1, 'No':0})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDWdlL24yBQi"
      },
      "source": [
        "# VVVFeature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HGL_OYNsyFsv"
      },
      "outputs": [],
      "source": [
        "services = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
        "            'StreamingTV', 'StreamingMovies']\n",
        "df['num_services'] = df[services].sum(axis=1)\n",
        "df['revenue_proxy'] = df['MonthlyCharges'] * df['tenure']\n",
        "df['contract_tenure'] = df['Contract'] * df['tenure']\n",
        "df['tenure_squared'] = df['tenure'] ** 2\n",
        "df['tenure_cubed'] = df['tenure'] ** 3\n",
        "df['is_MTM'] = (df['Contract'] == 3).astype(int) # Assuming 3 represents Month-to-month\n",
        "df['high_charge'] = (df['MonthlyCharges'] > df['MonthlyCharges'].mean()).astype(int)\n",
        "df['MTM_high_charge'] = df['is_MTM'] * df['high_charge']\n",
        "df['log_TotalCharges'] = np.log1p(df['TotalCharges'])\n",
        "df['log_tenure'] = np.log1p(df['tenure'])\n",
        "df['log_MonthlyCharges'] = np.log1p(df['MonthlyCharges'])\n",
        "df['log_num_services'] = np.log1p(df['num_services'])\n",
        "df['log_revenue_proxy'] = np.log1p(df['revenue_proxy'])\n",
        "df['log_contract_tenure'] = np.log1p(df['contract_tenure'])\n",
        "df['log_MTM_high_charge'] = np.log1p(df['MTM_high_charge'])\n",
        "df['log_age'] = np.log1p(df['SeniorCitizen'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Auk1ylrmkiXR"
      },
      "outputs": [],
      "source": [
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "datasets = create_kfold_datasets(X, y, n_splits=5, random_state=42)\n",
        "predictions_test = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROMYsPS7erBP"
      },
      "source": [
        "# 1 Logistic Regression ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-MqNxyze1iX",
        "outputId": "906705fc-0105-4e7e-cbb5-8d2451b2a8b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best threshold: 0.2141 with F1 score: 0.6479\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.69      0.79       796\n",
            "           1       0.53      0.84      0.65       329\n",
            "\n",
            "    accuracy                           0.73      1125\n",
            "   macro avg       0.72      0.76      0.72      1125\n",
            "weighted avg       0.80      0.73      0.75      1125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "\n",
        "\n",
        "# Train and predict using k-fold cross-validation\n",
        "def model1(X_train, X_test, y_train, y_test):\n",
        "    log_reg = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, solver = 'saga', penalty = 'l1'))\n",
        "    log_reg2 = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, class_weight= 'balanced', solver = 'saga', penalty = 'l1'))\n",
        "    alpha = 0.8\n",
        "    beta = 0.5\n",
        "    trained_model = train_model(X_train, y_train, log_reg)\n",
        "    trained_model2 = train_model(X_train, y_train, log_reg2)\n",
        "    y_train_probs1 = trained_model.predict_proba(X_train)[:, 1]\n",
        "    y_train_probs2 = trained_model2.predict_proba(X_train)[:, 1]\n",
        "    y_train_probs = (alpha * y_train_probs1 + beta * y_train_probs2) / 2\n",
        "\n",
        "    y_probs1 = trained_model.predict_proba(X_test)[:, 1]\n",
        "    y_probs2 = trained_model2.predict_proba(X_test)[:, 1]\n",
        "    y_probs = ( alpha * y_probs1 + beta * y_probs2) / 2\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    threshold = thresholds[best_threshold_index]\n",
        "    print(f\"Best threshold: {threshold:.4f} with F1 score: {f1_scores_thresholds[best_threshold_index]:.4f}\")\n",
        "    y_pred = (y_probs >= threshold).astype(int)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    print(report)\n",
        "    return (y_train_probs, y_probs)\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model1(X_train, X_test, y_train, y_test)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzSzbdEAnjYv"
      },
      "source": [
        "# 2 Decision Tree Classifier ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AysLpHg_ngqJ",
        "outputId": "21ad22aa-a5ff-4aca-aeae-bd5950ec9751"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.72      0.79       796\n",
            "           1       0.52      0.74      0.61       329\n",
            "\n",
            "    accuracy                           0.73      1125\n",
            "   macro avg       0.70      0.73      0.70      1125\n",
            "weighted avg       0.77      0.73      0.74      1125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "def model2(X_train, X_test, y_train, y_test):\n",
        "    dt_classifier = DecisionTreeClassifier(class_weight='balanced', max_depth=3, min_samples_leaf=1, min_samples_split=2)\n",
        "    trained_dt_model = train_model(X_train, y_train, dt_classifier)\n",
        "    y_pred_dt, y_pred_proba_dt, score, report = predict_model(X_test, y_test, trained_dt_model)\n",
        "    y_train_pred_proba_dt = trained_dt_model.predict_proba(X_train)[:, 1]\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba_dt)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    threshold = thresholds[best_threshold_index]\n",
        "    print(classification_report(y_test, y_pred_dt))\n",
        "    return (y_train_pred_proba_dt, y_pred_proba_dt)\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model2(X_train, X_test, y_train, y_test)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIYGP3GeqD7N"
      },
      "source": [
        "# 3 Random Forest Classifier ✅\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nloV0sboGSU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHvsh6dCqL_4",
        "outputId": "a6139b6e-151b-49be-af5b-70d5f9e8bc6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.76      0.81       796\n",
            "           1       0.56      0.76      0.64       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.72      0.76      0.73      1125\n",
            "weighted avg       0.79      0.76      0.76      1125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#param_grid = {'n_estimators': [100, 200],'max_depth': [6, 10, None],'min_samples_leaf': [1, 5, 10],'class_weight': [None, 'balanced', {0:1.0, 1:2.5}]}\n",
        "#grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "\n",
        "\n",
        "def model3(X_train, X_test, y_train, y_test):\n",
        "    rf_classifier = RandomForestClassifier(random_state=42, class_weight='balanced', max_depth=6, min_samples_leaf=1, n_estimators=100)\n",
        "    trained_rf_model = train_model(X_train, y_train, rf_classifier)\n",
        "    y_pred_dt, y_pred_proba_dt, score, report = predict_model(X_test, y_test, trained_rf_model)\n",
        "    y_train_pred_proba_dt = trained_rf_model.predict_proba(X_train)[:, 1]\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba_dt)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    threshold = thresholds[best_threshold_index]\n",
        "    print(classification_report(y_test, y_pred_dt))\n",
        "    return (y_train_pred_proba_dt, y_pred_proba_dt)\n",
        "\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model3(X_train, X_test, y_train, y_test)\n",
        "    break\n",
        "#0.64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehHCwJg9svR9"
      },
      "source": [
        "# 4 Gradient Boosting Classifier ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHhGS_I0s13i",
        "outputId": "f86822f7-5e5a-412c-b175-aba911a3e037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.73      0.81       796\n",
            "           1       0.55      0.78      0.64       329\n",
            "\n",
            "    accuracy                           0.75      1125\n",
            "   macro avg       0.72      0.76      0.73      1125\n",
            "weighted avg       0.79      0.75      0.76      1125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def model4(X_train, X_test, y_train, y_test):\n",
        "    alpha = 0.8\n",
        "    beta = 0.9\n",
        "    sample_weights = np.where(y_train == 1, 2.5, 1.0)\n",
        "    model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "    model.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "    model2 = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=10, random_state=42)\n",
        "    model2.fit(X_train, y_train)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "    #y_pred = (y_proba >= threshold).astype(int)\n",
        "    y_proba2 = model2.predict_proba(X_test)[:, 1]\n",
        "    #y_pred2 = (y_proba2 >= threshold).astype(int)\n",
        "    y_proba3 = alpha * y_proba + beta * y_proba2\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_proba3)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    threshold = thresholds[best_threshold_index]\n",
        "    y_pred3 = (y_proba3 >= threshold).astype(int)\n",
        "\n",
        "    y_train_proba = model.predict_proba(X_train)[:, 1]\n",
        "    y_train_proba2 = model2.predict_proba(X_train)[:, 1]\n",
        "    y_train_proba3 = alpha * y_train_proba + beta * y_train_proba2\n",
        "    print(classification_report(y_test, y_pred3))\n",
        "    return (y_train_proba3, y_proba3)\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model4(X_train, X_test, y_train, y_test)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX9ZBBa3exOJ"
      },
      "source": [
        "# 5 GaussianNB() ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huWx0cQbyaHL",
        "outputId": "84b86f4d-3863-4af4-be2c-c5d6b284d459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83       796\n",
            "           1       0.59      0.60      0.60       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.71      0.72      0.71      1125\n",
            "weighted avg       0.76      0.76      0.76      1125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "def model5(X_train, X_test, y_train, y_test):\n",
        "    gnb = GaussianNB()\n",
        "    calibrated_gnb = CalibratedClassifierCV(gnb, method='sigmoid', cv=5)  # Use sigmoid calibration\n",
        "    calibrated_gnb.fit(X_train, y_train)\n",
        "    y_pred_proba = calibrated_gnb.predict_proba(X_test)[:, 1]\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "    y_train_pred = calibrated_gnb.predict_proba(X_train)[:, 1]\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    return (y_train_pred, y_pred_proba)\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model5(X_train, X_test, y_train, y_test)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGfm8Tsl0Pxe"
      },
      "source": [
        "    #6 K neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFp5I9ir0UBb",
        "outputId": "6cbd0593-acde-4a02-ca4d-c365cdb58c42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN Classifier:\n",
            "KNeighborsClassifier(metric='manhattan', n_neighbors=60, weights='distance')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.88      0.83       796\n",
            "           1       0.60      0.43      0.51       329\n",
            "\n",
            "    accuracy                           0.75      1125\n",
            "   macro avg       0.70      0.66      0.67      1125\n",
            "weighted avg       0.74      0.75      0.74      1125\n",
            "\n",
            "Best threshold for KNN: 0.2637954367830825\n",
            "KNN Classifier:\n",
            "KNeighborsClassifier(metric='manhattan', n_neighbors=60, weights='distance')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       831\n",
            "           1       0.58      0.46      0.51       294\n",
            "\n",
            "    accuracy                           0.77      1125\n",
            "   macro avg       0.70      0.67      0.68      1125\n",
            "weighted avg       0.76      0.77      0.76      1125\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-39cba84c2bc8>:23: RuntimeWarning: invalid value encountered in divide\n",
            "  f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best threshold for KNN: 0.9367707629710854\n",
            "KNN Classifier:\n",
            "KNeighborsClassifier(metric='manhattan', n_neighbors=60, weights='distance')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.91      0.87       834\n",
            "           1       0.65      0.44      0.53       291\n",
            "\n",
            "    accuracy                           0.79      1125\n",
            "   macro avg       0.73      0.68      0.70      1125\n",
            "weighted avg       0.78      0.79      0.78      1125\n",
            "\n",
            "Best threshold for KNN: 0.362505957152888\n",
            "KNN Classifier:\n",
            "KNeighborsClassifier(metric='manhattan', n_neighbors=60, weights='distance')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87       849\n",
            "           1       0.60      0.43      0.50       276\n",
            "\n",
            "    accuracy                           0.79      1125\n",
            "   macro avg       0.72      0.67      0.69      1125\n",
            "weighted avg       0.78      0.79      0.78      1125\n",
            "\n",
            "Best threshold for KNN: 0.3270350404849127\n",
            "KNN Classifier:\n",
            "KNeighborsClassifier(metric='manhattan', n_neighbors=60, weights='distance')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       818\n",
            "           1       0.61      0.52      0.56       306\n",
            "\n",
            "    accuracy                           0.78      1124\n",
            "   macro avg       0.72      0.70      0.70      1124\n",
            "weighted avg       0.77      0.78      0.77      1124\n",
            "\n",
            "Best threshold for KNN: 0.3658699837792592\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    param_grid = {\n",
        "        'n_neighbors': [60],  # Example values, adjust as needed\n",
        "        'weights': ['uniform', 'distance'],  # Example values\n",
        "        'metric': ['euclidean', 'manhattan']  # Example values\n",
        "    }\n",
        "    knn = KNeighborsClassifier()\n",
        "    grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='f1') # Use 5-fold cross-validation\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_knn = grid_search.best_estimator_\n",
        "    y_pred_knn = best_knn.predict(X_test)\n",
        "\n",
        "    print(\"KNN Classifier:\")\n",
        "    print(grid_search.best_estimator_)\n",
        "    print(classification_report(y_test, y_pred_knn))\n",
        "\n",
        "    # Find the best threshold for KNN\n",
        "    y_pred_proba_knn = best_knn.predict_proba(X_test)[:, 1]\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba_knn)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold_knn = thresholds[best_threshold_index]\n",
        "    print(f\"Best threshold for KNN: {best_threshold_knn}\")\n",
        "\n",
        "    # ... (Rest of your code within the loop)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3LQ1qGM3M4w"
      },
      "source": [
        "# 7 SVC (no idea now)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PkVGW4T3QRn"
      },
      "outputs": [],
      "source": [
        "# prompt: use svc and grid search to predict ytest\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "# Assuming X_train, X_test, y_train, y_test are defined from your k-fold\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    # Create an SVC classifier\n",
        "    svc = SVC(probability=True)  # Enable probability estimates\n",
        "\n",
        "    # Define the parameter grid for GridSearchCV\n",
        "    param_grid = {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'kernel': ['linear', 'rbf', 'poly'],\n",
        "        'gamma': ['scale', 'auto', 0.1, 1]\n",
        "    }\n",
        "\n",
        "    # Perform GridSearchCV to find the best hyperparameters\n",
        "    grid_search = GridSearchCV(svc, param_grid, scoring='f1')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best estimator (SVC model with the best hyperparameters)\n",
        "    best_svc = grid_search.best_estimator_\n",
        "\n",
        "    # Predict on the test set using the best SVC model\n",
        "    y_pred = best_svc.predict(X_test)\n",
        "    y_pred_proba = best_svc.predict_proba(X_test)[:,1]\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    print(f\"Best threshold for SVC: {best_threshold}\")\n",
        "    y_pred_thresh = (y_pred_proba >= best_threshold).astype(int)\n",
        "\n",
        "    print(classification_report(y_test, y_pred_thresh))\n",
        "\n",
        "    break #remove to run for all folds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj6bL5R5eNiq"
      },
      "source": [
        "# 8 XGBoost ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rigozv3eTBH",
        "outputId": "e234d89c-3969-4e7c-dab2-54da6637eed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.70      0.79       796\n",
            "           1       0.52      0.80      0.63       329\n",
            "\n",
            "    accuracy                           0.73      1125\n",
            "   macro avg       0.71      0.75      0.71      1125\n",
            "weighted avg       0.79      0.73      0.74      1125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "from sklearn.metrics import confusion_matrix\n",
        "def model8(X_train, X_test, y_train, y_test):\n",
        "    xgb_model = XGBClassifier(random_state=42)\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'subsample': [0.8, 1.0],  # Example values\n",
        "        'colsample_bytree': [0.8, 1.0], # Example values\n",
        "    }\n",
        "    grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='f1', cv=3, n_jobs=-1) # Use 3-fold to speed it up\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best estimator\n",
        "    best_xgb_model = grid_search.best_estimator_\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = best_xgb_model.predict(X_test)\n",
        "    y_pred_proba = best_xgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    y_pred_thresh = (y_pred_proba >= best_threshold).astype(int)\n",
        "    y_train_pred = best_xgb_model.predict_proba(X_train)[:, 1]\n",
        "    print(classification_report(y_test, y_pred_thresh))\n",
        "    return (y_train_pred, y_pred_proba)\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model8(X_train, X_test, y_train, y_test)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUit-iUFeT--"
      },
      "source": [
        "# 9 Extra trees ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eBx9HnIeWkv",
        "outputId": "dc7f459b-ba6e-4a6e-9505-b014f38a2efd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.72      0.80       796\n",
            "           1       0.54      0.82      0.65       329\n",
            "\n",
            "    accuracy                           0.75      1125\n",
            "   macro avg       0.72      0.77      0.73      1125\n",
            "weighted avg       0.80      0.75      0.76      1125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "\n",
        "def model9(X_train, X_test, y_train, y_test):\n",
        "    #et_model = ExtraTreesClassifier(random_state=42, class_weight = 'balanced')\n",
        "    best_et_model = ExtraTreesClassifier(random_state=42, class_weight='balanced', max_depth=10, min_samples_split=10, min_samples_leaf=2)\n",
        "    #best_et_model = ExtraTreesClassifier(random_state=42\n",
        "    '''param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [None, 10, 20],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4],\n",
        "    }\n",
        "    grid_search = GridSearchCV(estimator=et_model, param_grid=param_grid, scoring='f1', cv=3, n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_et_model = grid_search.best_estimator_'''\n",
        "    best_et_model.fit(X_train, y_train)\n",
        "    y_pred = best_et_model.predict(X_test)\n",
        "    y_pred_proba = best_et_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Evaluate the model\n",
        "    #print(classification_report(y_test, y_pred))\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1]+1e-8)\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    #print(f\"Best threshold for ExtraTrees: {best_threshold}\")\n",
        "    y_pred_thresh = (y_pred_proba >= best_threshold).astype(int)\n",
        "    y_train_pred = best_et_model.predict_proba(X_train)[:, 1]\n",
        "    print(classification_report(y_test, y_pred_thresh))\n",
        "    return (y_train_pred, y_pred_proba)\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model9(X_train, X_test, y_train, y_test)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYR28i6ieW1l"
      },
      "source": [
        "# 10 MultiLayer Perception ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "466r3hMDebkU",
        "outputId": "48c10099-48b6-45b0-c0d8-13634fe35887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.51      0.66       796\n",
            "           1       0.43      0.91      0.59       329\n",
            "\n",
            "    accuracy                           0.63      1125\n",
            "   macro avg       0.68      0.71      0.62      1125\n",
            "weighted avg       0.78      0.63      0.64      1125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "'''param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (64,), (64, 32), (128, 64)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'solver': ['adam'],\n",
        "    'alpha': [0.0001, 0.001, 0.01, 0,1],\n",
        "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
        "    'learning_rate': ['constant', 'adaptive']\n",
        "}\n",
        "\n",
        "mlp = MLPClassifier(max_iter=500, random_state=42) # Increased max_iter\n",
        "grid_search = GridSearchCV(mlp, param_grid, scoring='f1', cv=3, n_jobs=-1) # Use 3-fold for speed'''\n",
        "\n",
        "def model10(X_train, X_test, y_train, y_test):\n",
        "    weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
        "    best_mlp = MLPClassifier(alpha=0.001, hidden_layer_sizes=(50,), max_iter=500,\n",
        "              random_state=42)\n",
        "    best_mlp.fit(X_train, y_train)\n",
        "\n",
        "    #best_mlp = grid_search.best_estimator_\n",
        "\n",
        "    y_pred = best_mlp.predict(X_test)\n",
        "    y_pred_proba = best_mlp.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    #print(classification_report(y_test, y_pred))\n",
        "    #print(best_mlp)\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    #print(f\"Best threshold for MLP: {best_threshold}\")\n",
        "    y_pred_thresh = (y_pred_proba >= best_threshold).astype(int)\n",
        "    y_train_pred = best_mlp.predict_proba(X_train)[:, 1]\n",
        "    print(classification_report(y_test, y_pred_thresh))\n",
        "    return (y_train_pred, y_pred_proba)\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model10(X_train, X_test, y_train, y_test)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhG89sXlecyi"
      },
      "source": [
        "# 11 Light GBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IftgRxerefkX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#!pip install lightgbm\n",
        "\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score, precision_recall_curve\n",
        "\n",
        "def model11(X_train, X_test, y_train, y_test):\n",
        "    '''param_grid = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'learning_rate': [0.01, 0.1],\n",
        "        'max_depth': [3, 5],\n",
        "        'num_leaves': [31, 50],\n",
        "        'min_child_samples': [20, 50],\n",
        "        'reg_alpha': [0, 0.1],\n",
        "        'reg_lambda': [0, 0.1],\n",
        "        'class_weight': ['balanced', None]\n",
        "    }\n",
        "    lgb_model = lgb.LGBMClassifier(random_state=42)\n",
        "    grid_search = GridSearchCV(estimator=lgb_model, param_grid=param_grid, scoring='f1', cv=3, n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_lgb_model = grid_search.best_estimator_'''\n",
        "\n",
        "    best_lgm_model = lgb.LGBMClassifier(class_weight='balanced', learning_rate=0.01, max_depth=5,\n",
        "               n_estimators=200, random_state=42, reg_alpha=0.1,\n",
        "               reg_lambda=0.1)\n",
        "    y_pred_proba = best_lgb_model.predict_proba(X_test)[:, 1]\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "\n",
        "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(best_lgb_model)\n",
        "\n",
        "    return y_pred_proba - best_threshold\n",
        "\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model11(X_train, X_test, y_train, y_test)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oI4_JbaegM3"
      },
      "source": [
        "# 12 Multinomial nb ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BI8mZZxekHJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "def model12(X_train, X_test, y_train, y_test):\n",
        "    mnb = MultinomialNB()\n",
        "    param_grid = {\n",
        "        'alpha': [0.1, 0.5, 1.0, 2.0],  # Laplace smoothing parameter\n",
        "        'fit_prior': [True, False],  # Whether to learn class prior probabilities\n",
        "        'class_prior': [\n",
        "          None,\n",
        "          [0.5, 0.5],\n",
        "          [0.7, 0.3],\n",
        "          [0.3, 0.7]\n",
        "        ]\n",
        "    }\n",
        "    grid_search = GridSearchCV(mnb, param_grid, scoring='f1', cv=5) # Use 5-fold cross-validation\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_mnb = grid_search.best_estimator_\n",
        "    print(best_mnb)\n",
        "\n",
        "    y_pred_proba = best_mnb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    print(f\"Best threshold for MultinomialNB: {best_threshold}\")\n",
        "\n",
        "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(best_mnb)\n",
        "    return y_pred_proba - best_threshold\n",
        "\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model12(X_train, X_test, y_train, y_test)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLUrXYfGekxO"
      },
      "source": [
        "# 13 Bernouli nb ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhyJrT3MymPr"
      },
      "outputs": [],
      "source": [
        "# prompt: use bernouli nb and grid search class weight to predict _test and maximize f1\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def model13(X_train, X_test, y_train, y_test):\n",
        "    bnb = BernoulliNB()\n",
        "    param_grid = {\n",
        "        'alpha': [0.1, 0.5, 1.0, 2.0],\n",
        "        'binarize': [0.0, 0.5, 1.0],\n",
        "        'fit_prior': [True, False],\n",
        "        'class_prior': [\n",
        "          None,\n",
        "          [0.5, 0.5],\n",
        "          [0.7, 0.3],\n",
        "          [0.3, 0.7]\n",
        "        ]\n",
        "    }\n",
        "    grid_search = GridSearchCV(bnb, param_grid, scoring='f1', cv=5)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_bnb = grid_search.best_estimator_\n",
        "    print(best_bnb)\n",
        "\n",
        "    y_pred_proba = best_bnb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    print(f\"Best threshold for BernoulliNB: {best_threshold}\")\n",
        "\n",
        "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    return y_pred_proba - best_threshold\n",
        "\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model13(X_train, X_test, y_train, y_test)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtAX7E1IzzrN"
      },
      "source": [
        "# 14 CatBoost ✅(grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY2OQRki0gFz",
        "outputId": "8e1aaf3e-2b69-458c-d58d-0f83acfe2263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n",
            "{'class_weights': [1, 2], 'depth': 4, 'iterations': 200, 'l2_leaf_reg': 1, 'learning_rate': 0.01}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.76      0.82       796\n",
            "           1       0.56      0.75      0.64       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.72      0.75      0.73      1125\n",
            "weighted avg       0.79      0.76      0.76      1125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "!pip install catboost\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def model14(X_train, X_test, y_train, y_test):\n",
        "    model = CatBoostClassifier(random_seed=42, verbose=0)\n",
        "\n",
        "    param_grid = {\n",
        "        'iterations': [100, 200],\n",
        "        'learning_rate': [0.01, 0.1],\n",
        "        'depth': [4, 6],\n",
        "        'l2_leaf_reg': [1, 3],\n",
        "        'class_weights': [[1, 1], [1, 2], [1, 3], [1,4], [1,5]] # Example class weights\n",
        "    }\n",
        "    grid_search = GridSearchCV(model, param_grid, scoring='f1', cv=3, n_jobs=-1) # Use 3-fold to speed up\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    print(grid_search.best_params_)\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "    y_train_proba = best_model.predict_proba(X_train)[:, 1]\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    #print(best_model)\n",
        "    return (y_train_proba, y_pred_proba)\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model14(X_train, X_test, y_train, y_test)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVIB9X0Gz0pW"
      },
      "source": [
        "# 15 TabNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJSNVQN306tQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#!pip install pytorch-tabnet\n",
        "\n",
        "import torch\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "# Define the parameter grid for TabNet\n",
        "\n",
        "\n",
        "def model15(X_train, X_test, y_train, y_test):\n",
        "    param_grid = {\n",
        "        'n_d': [8, 16],\n",
        "        'n_a': [8, 16],\n",
        "        'n_steps': [3, 5],\n",
        "        'gamma': [1.3, 1.5],\n",
        "        'n_independent': [1,2],\n",
        "        'lambda_sparse': [1e-3, 1e-4],\n",
        "        'optimizer_fn': [torch.optim.Adam],\n",
        "        'optimizer_params': [dict(lr=2e-2)],\n",
        "        'mask_type': ['entmax'],\n",
        "        'scheduler_params': [dict(mode=\"min\", patience=5, min_lr=1e-5, factor=0.9)],\n",
        "        'scheduler_fn': [torch.optim.lr_scheduler.ReduceLROnPlateau],\n",
        "        'verbose': [10]\n",
        "    }\n",
        "    tabnet_model = TabNetClassifier()\n",
        "    f1_scorer = make_scorer(f1_score, average='weighted')\n",
        "    grid_search = GridSearchCV(estimator=tabnet_model, param_grid=param_grid, scoring=f1_scorer, cv=3, n_jobs=-1, verbose=1)\n",
        "    #sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
        "\n",
        "    grid_search.fit(X_train.values, y_train.values, eval_set=[(X_test.values, y_test.values)], eval_metric=['f1'])\n",
        "\n",
        "    best_tabnet_model = grid_search.best_estimator_\n",
        "    y_pred = best_tabnet_model.predict(X_test.values)\n",
        "    y_pred_proba = best_tabnet_model.predict_proba(X_test.values)[:,1]\n",
        "\n",
        "    print(\"Classification Report for TabNet:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    y_pred_thresh = (y_pred_proba >= best_threshold).astype(int)\n",
        "\n",
        "    print(classification_report(y_test, y_pred_thresh))\n",
        "\n",
        "    print(best_tabnet_model)\n",
        "    return y_pred_proba - best_threshold\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model15(X_train, X_test, y_train, y_test)\n",
        "    break # Remove to run for all folds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaeesu84z3u7"
      },
      "source": [
        "# 16 Node2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLrOvZun1h_e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "!pip install node2vec\n",
        "\n",
        "import networkx as nx\n",
        "from node2vec import Node2Vec\n",
        "\n",
        "def create_graph_from_dataframe(df):\n",
        "    graph = nx.Graph()\n",
        "    for index, row in df.iterrows():\n",
        "      graph.add_node(index, features=row.to_dict()) # or use a subset of columns\n",
        "    for i in range(len(df)):\n",
        "        for j in range(i + 1, len(df)):\n",
        "            similarity = np.dot(df.iloc[i], df.iloc[j])/(np.linalg.norm(df.iloc[i])*np.linalg.norm(df.iloc[j]))\n",
        "            if similarity > 0.5: # Example threshold\n",
        "                graph.add_edge(i, j, weight=similarity)\n",
        "    return graph\n",
        "\n",
        "def get_node2vec_embeddings(graph, dimensions=64, walk_length=30, num_walks=200, workers=4):\n",
        "  node2vec = Node2Vec(graph, dimensions=dimensions, walk_length=walk_length, num_walks=num_walks, workers=workers)\n",
        "  model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
        "  embeddings = {node: model.wv[str(node)] for node in graph.nodes()}\n",
        "  return embeddings\n",
        "\n",
        "def model16(X_train, X_test, y_train, y_test):\n",
        "    train_graph = create_graph_from_dataframe(X_train)\n",
        "    embeddings_train = get_node2vec_embeddings(train_graph)\n",
        "    X_train_embeddings = np.array([embeddings_train[i] for i in range(len(X_train))])\n",
        "\n",
        "\n",
        "    test_graph = create_graph_from_dataframe(X_test)\n",
        "    embeddings_test = get_node2vec_embeddings(test_graph)\n",
        "    X_test_embeddings = np.array([embeddings_test[i] for i in range(len(X_test))])\n",
        "\n",
        "\n",
        "    param_grid = {\n",
        "        'class_weight': [None, 'balanced', {0:1, 1:10}],\n",
        "        # ... other hyperparameters for your classifier\n",
        "    }\n",
        "\n",
        "    # Example classifier: Logistic Regression\n",
        "    clf = LogisticRegression()\n",
        "\n",
        "    grid_search = GridSearchCV(clf, param_grid, scoring='f1', cv=3)  # Use 3-fold for speed\n",
        "\n",
        "    grid_search.fit(X_train_embeddings, y_train)\n",
        "    best_clf = grid_search.best_estimator_\n",
        "    y_pred = best_clf.predict(X_test_embeddings)\n",
        "    y_pred_proba = best_clf.predict_proba(X_test_embeddings)[:, 1]\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    y_pred_thresh = (y_pred_proba >= best_threshold).astype(int)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(best_clf)\n",
        "    return y_pred_proba - best_threshold\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model16(X_train, X_test, y_train, y_test)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AsbpV6iz1Ci"
      },
      "source": [
        "# 17 NGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBU9IFAa1al-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "!pip install ngboost\n",
        "from ngboost import NGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "def model17(X_train, X_test, y_train, y_test):\n",
        "    param_grid = {\n",
        "        'Dist': ['Normal', 'LogNormal'],\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.1],\n",
        "        'minibatch_frac': [0.5, 1.0],\n",
        "        'natural_gradient': [True, False],\n",
        "        'verbose': [False],\n",
        "        'Base': [DecisionTreeClassifier(max_depth=3)] # Example base learner, you can experiment\n",
        "    }\n",
        "    ngb_model = NGBClassifier()\n",
        "    grid_search = GridSearchCV(estimator=ngb_model, param_grid=param_grid, scoring='f1', cv=3, n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_ngb_model = grid_search.best_estimator_\n",
        "    y_pred_proba = best_ngb_model.predict_proba(X_test)[:, 1]\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(best_ngb_model)\n",
        "\n",
        "    return y_pred_proba - best_threshold\n",
        "\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "  model17(X_train, X_test, y_train, y_test)\n",
        "  break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaePttkvz1md"
      },
      "source": [
        "# 18 DeepFM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gZxPjvr2RdI"
      },
      "outputs": [],
      "source": [
        "# prompt: use DeepFM and grid search (including but not limited to class weight) to predict y_test and maximize f1\n",
        "\n",
        "!pip install deepctr\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from deepctr.models import DeepFM\n",
        "from deepctr.feature_column import SparseFeat, DenseFeat, get_feature_names\n",
        "\n",
        "# Assuming your data is preprocessed as in the previous example\n",
        "# ... (Your existing code for data loading and preprocessing)\n",
        "\n",
        "# Create feature columns\n",
        "sparse_features = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService',\n",
        "                   'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
        "                   'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
        "dense_features = ['tenure', 'MonthlyCharges', 'TotalCharges', 'num_services', 'revenue_proxy',\n",
        "                  'contract_tenure', 'tenure_squared', 'tenure_cubed', 'is_MTM', 'high_charge',\n",
        "                  'MTM_high_charge', 'log_TotalCharges', 'log_tenure', 'log_MonthlyCharges',\n",
        "                  'log_num_services', 'log_revenue_proxy', 'log_contract_tenure',\n",
        "                  'log_MTM_high_charge', 'log_age']\n",
        "\n",
        "\n",
        "for feat in sparse_features:\n",
        "    lbe = LabelEncoder()\n",
        "    X[feat] = lbe.fit_transform(X[feat])\n",
        "mms = MinMaxScaler(feature_range=(0,1))\n",
        "X[dense_features] = mms.fit_transform(X[dense_features])\n",
        "\n",
        "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=X[feat].nunique(),embedding_dim=4)\n",
        "                        for i,feat in enumerate(sparse_features)] + [DenseFeat(feat, 1,)\n",
        "                        for feat in dense_features]\n",
        "\n",
        "dnn_feature_columns = fixlen_feature_columns\n",
        "linear_feature_columns = fixlen_feature_columns\n",
        "\n",
        "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'dnn_hidden_units': [(128, 64), (256, 128)],\n",
        "    'l2_reg_linear': [0.001, 0.01],\n",
        "    'l2_reg_embedding': [0.001, 0.01],\n",
        "    'l2_reg_dnn': [0, 0.001],\n",
        "    'dnn_dropout': [0, 0.1],\n",
        "    'class_weight': [{0:1, 1:1.5}, {0:1, 1:2}, 'balanced']\n",
        "}\n",
        "\n",
        "# Initialize DeepFM model\n",
        "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary')\n",
        "\n",
        "# Perform GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "grid_search = GridSearchCV(model, param_grid, scoring='f1', cv=3, n_jobs=-1, verbose=1) # Use 3-fold for speed\n",
        "grid_search.fit(X_train[feature_names], y_train, )\n",
        "\n",
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_proba = best_model.predict(X_test[feature_names], batch_size=256)\n",
        "\n",
        "# Find the best threshold for maximizing F1-score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "best_threshold = thresholds[best_threshold_index]\n",
        "\n",
        "y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcMQiU-uz1_G"
      },
      "source": [
        "# 19 RuleFit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vz-z8TNz8124"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "!pip install rulefit\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from rulefit import RuleFit\n",
        "\n",
        "def model19(X_train, X_test, y_train, y_test):\n",
        "    # Define the parameter grid for RuleFit\n",
        "    param_grid = {\n",
        "        'max_rules': [50, 100],  # Maximum number of rules to generate\n",
        "        'tree_size': [2, 4],      # Maximum size of each rule tree\n",
        "        'sample_fract': [0.7, 0.9], # Fraction of samples to use for rule generation\n",
        "        'memory_par': [0.01, 0.05], # Memory parameter for rule generation\n",
        "        'exp_rand_tree_size': [True, False], # Use randomized tree sizes\n",
        "        'class_weight': ['balanced', None],\n",
        "    }\n",
        "\n",
        "    # Initialize RuleFit\n",
        "    rulefit_model = RuleFit()\n",
        "\n",
        "    # Perform GridSearchCV\n",
        "    grid_search = GridSearchCV(estimator=rulefit_model, param_grid=param_grid, scoring='f1', cv=3, n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best model\n",
        "    best_rulefit_model = grid_search.best_estimator_\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred_proba = best_rulefit_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Find the best threshold for maximizing F1-score\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "\n",
        "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(best_rulefit_model)\n",
        "    return y_pred_proba - best_threshold\n",
        "\n",
        "\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model19(X_train, X_test, y_train, y_test)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYSnDxJMz2bW"
      },
      "source": [
        "# 20 VIME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDOU22kl9YOC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "!pip install VIME\n",
        "\n",
        "import VIME\n",
        "\n",
        "def model20(X_train, X_test, y_train, y_test):\n",
        "    # Initialize VIME model\n",
        "    vime_model = VIME.VIME()\n",
        "\n",
        "    # Define parameter grid for GridSearchCV (adjust as needed)\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100],  # Example values, adjust based on your data\n",
        "        'learning_rate': [0.01, 0.1],  # Example values\n",
        "        'max_depth': [3, 5],  # Example values\n",
        "        'class_weight': [None, 'balanced'] # Include class_weight\n",
        "    }\n",
        "\n",
        "    # Use GridSearchCV to find optimal hyperparameters\n",
        "    grid_search = GridSearchCV(vime_model, param_grid, scoring='f1', cv=3, n_jobs=-1)  # Use 3-fold for speed\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_vime_model = grid_search.best_estimator_\n",
        "    y_pred_proba = best_vime_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(best_vime_model)\n",
        "    return y_pred_proba - best_threshold\n",
        "\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model20(X_train, X_test, y_train, y_test)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gac7TSQkz24Q"
      },
      "source": [
        "# 21 Logistic Regression with Polynomial Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNjieBvh98AZ"
      },
      "outputs": [],
      "source": [
        "# prompt: use logistic regression with polynomial features and grid search (including but not limited to class weight) to predict y_test and maximize f1\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create polynomial features\n",
        "poly = PolynomialFeatures(degree=2) # Example degree, adjust as needed\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# Define the parameter grid for Logistic Regression with polynomial features\n",
        "param_grid = {\n",
        "    'logisticregression__C': [0.1, 1, 10],  # Regularization parameter\n",
        "    'logisticregression__class_weight': [None, 'balanced'], # Class weights\n",
        "    'logisticregression__solver': ['liblinear', 'saga'], # Solvers\n",
        "    'logisticregression__penalty': ['l1', 'l2'] # Penalty\n",
        "}\n",
        "\n",
        "# Create a pipeline with polynomial features and Logistic Regression\n",
        "log_reg_poly = make_pipeline(StandardScaler(), PolynomialFeatures(degree=2), LogisticRegression(max_iter=1000))\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search_poly = GridSearchCV(log_reg_poly, param_grid, scoring='f1', cv=5) # Use 5-fold cross-validation\n",
        "grid_search_poly.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Get the best model\n",
        "best_log_reg_poly = grid_search_poly.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_proba = best_log_reg_poly.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Find the best threshold for maximizing F1-score\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)\n",
        "best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "best_threshold = thresholds[best_threshold_index]\n",
        "\n",
        "y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "print(classification_report(y_test, y_pred))\n",
        "best_log_reg_poly\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsBMYYwCz3WE"
      },
      "source": [
        "# 22 Factorization Machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OT5ATQ0d-Cq8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "!pip install pyfm\n",
        "\n",
        "from pyfm import pylibfm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "\n",
        "def model22(X_train, X_test, y_train, y_test):\n",
        "    # Convert pandas DataFrames to numpy arrays\n",
        "    X_train = X_train.values\n",
        "    X_test = X_test.values\n",
        "    y_train = y_train.values\n",
        "    y_test = y_test.values\n",
        "\n",
        "    # Define the parameter grid for Factorization Machines\n",
        "    param_grid = {\n",
        "        'num_factors': [8, 16, 32],\n",
        "        'num_iterations': [50, 100],\n",
        "        'learning_rate': [0.01, 0.1],\n",
        "        'regularization': [0.01, 0.1],\n",
        "        'class_weight': [{0:1, 1:1.5}, {0:1, 1:2}, 'balanced'] # Include class_weight\n",
        "        }\n",
        "\n",
        "    # Initialize Factorization Machines model\n",
        "    fm = pylibfm.FM()\n",
        "    f1_scorer = make_scorer(f1_score, average='weighted')\n",
        "\n",
        "    # Perform GridSearchCV\n",
        "    grid_search = GridSearchCV(fm, param_grid, scoring=f1_scorer, cv=3, n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best model\n",
        "    best_fm_model = grid_search.best_estimator_\n",
        "\n",
        "    # Predict probabilities on the test set\n",
        "    y_pred_proba = best_fm_model.predict(X_test)\n",
        "\n",
        "    # Find the best threshold for maximizing F1-score\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n",
        "    best_threshold_index = np.argmax(f1_scores_thresholds)\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "\n",
        "    y_pred = (y_pred_proba >= best_threshold).astype(int)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(best_fm_model)\n",
        "    return y_pred_proba - best_threshold\n",
        "\n",
        "for X_train, X_test, y_train, y_test in datasets:\n",
        "    model22(X_train, X_test, y_train, y_test)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDaHy2BCxyKi"
      },
      "source": [
        "# Meta Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9B7Mj2DMDGOc"
      },
      "outputs": [],
      "source": [
        "# Scikit-learn classifiers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# 1) Logistic Regression\n",
        "model1 = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, class_weight = 'balanced', solver = 'saga', penalty = 'l1', C = 0.5))\n",
        "# 2) Decision Tree\n",
        "#model2 = DecisionTreeClassifier(random_state=42)\n",
        "# 3) Random Forest\n",
        "model3 = RandomForestClassifier(random_state=42)\n",
        "# 4) Gradient Boosting (scikit-learn)\n",
        "model4 = GradientBoostingClassifier(random_state=42)\n",
        "# 5) Gaussian Naive Bayes\n",
        "model5 = GaussianNB()\n",
        "# 6) KNeighbors\n",
        "model6 = KNeighborsClassifier()\n",
        "# 7) SVM\n",
        "model7 = SVC(probability=True, random_state=42)\n",
        "# 8) XGBoost\n",
        "model8 = XGBClassifier(eval_metric='logloss', random_state=42)\n",
        "# 9) Extra Trees\n",
        "model9 = ExtraTreesClassifier(random_state=42)\n",
        "# 10) Multi-Layer Perceptron\n",
        "model10 = MLPClassifier(max_iter=300, random_state=42)\n",
        "# light gbm\n",
        "#multinomial nb\n",
        "#bernouli nb\n",
        "\n",
        "# Put them in a list for convenience\n",
        "models = [\n",
        "    (\"LogisticRegression\", model1),\n",
        "    #(\"DecisionTree\", model2),\n",
        "    #(\"RandomForest\", model3),\n",
        "    #(\"GradientBoosting\", model4),\n",
        "    (\"NaiveBayes\", model5),\n",
        "    #(\"KNN\", model6),\n",
        "    #(\"SVM\", model7),\n",
        "    #(\"XGB\", model8),\n",
        "    #(\"ExtraTrees\", model9),\n",
        "    (\"MLP\", model10)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBoknfBxy6m_"
      },
      "outputs": [],
      "source": [
        "# prompt: see which features impact churn the most\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'X_train' and 'model1' (Logistic Regression) are defined from the previous code\n",
        "\n",
        "# Fit the model (if not already fitted)\n",
        "for model in models:\n",
        "  model = model[1]\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # Get feature importances\n",
        "  feature_importances = model.coef_[0]\n",
        "\n",
        "  # Create a DataFrame for easier handling\n",
        "  feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
        "\n",
        "  # Sort by absolute importance (to see both positive and negative impacts)\n",
        "  feature_importance_df = feature_importance_df.reindex(feature_importance_df['Importance'].abs().sort_values(ascending=False).index)\n",
        "\n",
        "  # Plot the feature importances\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
        "  plt.title('Feature Importance (Logistic Regression)')\n",
        "  plt.xlabel('Importance')\n",
        "  plt.ylabel('Feature')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCdxGRKi18M1"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "feat_imp_rf = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
        "feat_imp_rf = feat_imp_rf.sort_values(ascending=False)\n",
        "\n",
        "print(\"Top 10 RandomForest features:\")\n",
        "print(feat_imp_rf.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fIH5yi6oTv8"
      },
      "source": [
        "# Meta Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyRq79bHDHeE"
      },
      "outputs": [],
      "source": [
        "train_preds = []\n",
        "for name, m in models:\n",
        "    train_preds.append(m.predict_proba(X_train)[:, 1])\n",
        "\n",
        "meta_X_train = pd.DataFrame(np.column_stack(train_preds), columns=[n for n,_ in models])\n",
        "meta_y_train = y_train\n",
        "\n",
        "meta_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "meta_model.fit(meta_X_train, meta_y_train)\n",
        "print(\"\\nMeta-model has been trained on stacked predictions of the 10 base models.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cUBhG5kDMDP"
      },
      "outputs": [],
      "source": [
        "# Combine base models' test predictions\n",
        "test_preds = []\n",
        "for name, m in models:\n",
        "    predictions_test = m.predict_proba(X_test)[:, 1]\n",
        "    test_preds.append(predictions_test)\n",
        "\n",
        "meta_X_test = pd.DataFrame(np.column_stack(test_preds), columns=[n for n,_ in models])\n",
        "\n",
        "# Predict using the meta-model\n",
        "meta_test_pred = meta_model.predict(meta_X_test)\n",
        "meta_test_prob = meta_model.predict_proba(meta_X_test)[:, 1]\n",
        "\n",
        "# Evaluate the final stacked model\n",
        "print(\"\\n***** Evaluation of the final (stacked) meta-model *****\")\n",
        "print(classification_report(y_test, meta_test_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOemoNMO5EW1"
      },
      "outputs": [],
      "source": [
        "models = [('1',model1), ('2', model2), ('3', model3), ('4', model4), ('5', model5), ('8', model8), ('9', model9), ('14', model14)]#, ('14', model14)]\n",
        "def stack_models(X_train, X_test, y_train, y_test, models):\n",
        "    X_train2 = X_train.copy()\n",
        "    X_test2 = X_test.copy()\n",
        "\n",
        "    for name, model in models:\n",
        "        X_train2[name], X_test2[name] = model(X_train, X_test, y_train, y_test)\n",
        "    for name, model in models:\n",
        "        X_train2['final'+name], X_test2['final'+name] = model(X_train2, X_test2, y_train, y_test)\n",
        "\n",
        "    return X_train2, X_test2, y_train, y_test\n",
        "\n",
        "\n",
        "def evalulate(X_train2, X_test2, y_train, y_test):\n",
        "\n",
        "    meta_model = LogisticRegression(max_iter=1000, class_weight='balanced',random_state=42, solver = 'saga', penalty = 'l1')\n",
        "    #meta_model = XGBClassifier(eval_metric='logloss', random_state=42)\n",
        "    #meta_model = RandomForestClassifier(random_state=42)\n",
        "    #meta_model = GradientBoostingClassifier(random_state=42)\n",
        "    meta_model.fit(X_train2, y_train)\n",
        "    meta_test_pred = meta_model.predict(X_test2)\n",
        "\n",
        "    print(\"\\n***** Evaluation of the final (stacked) meta-model *****\")\n",
        "    print(classification_report(y_test, meta_test_pred))\n",
        "    print(meta_model.coef_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufgqe-2k5lke",
        "outputId": "67a0c3ec-9516-4540-ec46-bc9c2691a2eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.69      0.79       796\n",
            "           1       0.53      0.84      0.65       329\n",
            "\n",
            "    accuracy                           0.73      1125\n",
            "   macro avg       0.72      0.76      0.72      1125\n",
            "weighted avg       0.80      0.73      0.75      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.72      0.79       796\n",
            "           1       0.52      0.74      0.61       329\n",
            "\n",
            "    accuracy                           0.73      1125\n",
            "   macro avg       0.70      0.73      0.70      1125\n",
            "weighted avg       0.77      0.73      0.74      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.76      0.81       796\n",
            "           1       0.56      0.76      0.64       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.72      0.76      0.73      1125\n",
            "weighted avg       0.79      0.76      0.76      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.73      0.81       796\n",
            "           1       0.55      0.78      0.64       329\n",
            "\n",
            "    accuracy                           0.75      1125\n",
            "   macro avg       0.72      0.76      0.73      1125\n",
            "weighted avg       0.79      0.75      0.76      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83       796\n",
            "           1       0.59      0.60      0.60       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.71      0.72      0.71      1125\n",
            "weighted avg       0.76      0.76      0.76      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.70      0.79       796\n",
            "           1       0.52      0.80      0.63       329\n",
            "\n",
            "    accuracy                           0.73      1125\n",
            "   macro avg       0.71      0.75      0.71      1125\n",
            "weighted avg       0.79      0.73      0.74      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.72      0.80       796\n",
            "           1       0.54      0.82      0.65       329\n",
            "\n",
            "    accuracy                           0.75      1125\n",
            "   macro avg       0.72      0.77      0.73      1125\n",
            "weighted avg       0.80      0.75      0.76      1125\n",
            "\n",
            "{'class_weights': [1, 2], 'depth': 4, 'iterations': 200, 'l2_leaf_reg': 1, 'learning_rate': 0.01}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.76      0.82       796\n",
            "           1       0.56      0.75      0.64       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.72      0.75      0.73      1125\n",
            "weighted avg       0.79      0.76      0.76      1125\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-3266553412>:30: RuntimeWarning: invalid value encountered in divide\n",
            "  f1_scores_thresholds = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83       796\n",
            "           1       0.00      0.00      0.00       329\n",
            "\n",
            "    accuracy                           0.71      1125\n",
            "   macro avg       0.35      0.50      0.41      1125\n",
            "weighted avg       0.50      0.71      0.59      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84       796\n",
            "           1       0.61      0.54      0.57       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.71      0.70      0.71      1125\n",
            "weighted avg       0.76      0.76      0.76      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.87      0.84       796\n",
            "           1       0.61      0.51      0.56       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.71      0.69      0.70      1125\n",
            "weighted avg       0.75      0.76      0.76      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84       796\n",
            "           1       0.61      0.54      0.57       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.71      0.70      0.71      1125\n",
            "weighted avg       0.76      0.76      0.76      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.78      0.81       796\n",
            "           1       0.56      0.66      0.61       329\n",
            "\n",
            "    accuracy                           0.75      1125\n",
            "   macro avg       0.70      0.72      0.71      1125\n",
            "weighted avg       0.76      0.75      0.75      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83       796\n",
            "           1       0.59      0.56      0.58       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.71      0.70      0.70      1125\n",
            "weighted avg       0.76      0.76      0.76      1125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.83      0.83       796\n",
            "           1       0.59      0.61      0.60       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.72      0.72      0.72      1125\n",
            "weighted avg       0.77      0.76      0.76      1125\n",
            "\n",
            "{'class_weights': [1, 3], 'depth': 4, 'iterations': 100, 'l2_leaf_reg': 3, 'learning_rate': 0.01}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.80      0.82       796\n",
            "           1       0.57      0.65      0.61       329\n",
            "\n",
            "    accuracy                           0.76      1125\n",
            "   macro avg       0.71      0.73      0.72      1125\n",
            "weighted avg       0.77      0.76      0.76      1125\n",
            "\n",
            "\n",
            "***** Evaluation of the final (stacked) meta-model *****\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.59      0.71       796\n",
            "           1       0.46      0.84      0.59       329\n",
            "\n",
            "    accuracy                           0.66      1125\n",
            "   macro avg       0.68      0.72      0.65      1125\n",
            "weighted avg       0.77      0.66      0.68      1125\n",
            "\n",
            "[[ 1.15492047e-06  1.82555200e-06  1.92125460e-09 -1.06757559e-06\n",
            "  -3.33342462e-05  2.27779841e-06  2.10236711e-06  9.24019193e-06\n",
            "  -1.18739910e-06  5.75104830e-08  4.98856896e-07 -1.01121016e-06\n",
            "   2.00830183e-06  2.05132863e-06 -3.31913586e-05  4.26120196e-06\n",
            "   5.69085962e-06  3.19582300e-04  2.65690601e-04  2.43172627e-06\n",
            "   2.78354758e-04 -1.16997039e-03 -9.11129189e-04  1.46466623e-06\n",
            "   0.00000000e+00  3.85222227e-06  0.00000000e+00  1.17102798e-05\n",
            "  -5.98811603e-07  1.44656731e-05  1.89550143e-06  1.17180598e-05\n",
            "  -4.79594582e-06  0.00000000e+00  1.26097661e-06  2.92101055e-06\n",
            "   4.51333507e-06  5.16515862e-06  1.62113891e-05  1.72230665e-06\n",
            "   5.95224075e-06  6.37995919e-06  4.02311794e-06  9.71390375e-06\n",
            "   1.49957019e-05  1.44249724e-05  2.54885186e-05  1.87676166e-06\n",
            "   9.75510040e-06  1.49944152e-05  1.46352715e-05]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "for i, (X_train, X_test, y_train, y_test) in enumerate(datasets):\n",
        "    X_train2, X_test2, y_train2, y_test2 = stack_models(X_train, X_test, y_train, y_test, models)\n",
        "    evalulate(X_train2, X_test2, y_train2, y_test2)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"test_data.csv\")\n",
        "customerID = df['customerID']\n",
        "if 'customerID' in df.columns:\n",
        "    df.drop('customerID', axis=1, inplace=True)\n",
        "if 'TotalCharges' in df.columns:\n",
        "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df.dropna(inplace=True)\n",
        "df['Contract'] = df['Contract'].map({'Month-to-month': 2, 'One year': 12, 'Two year': 24})\n",
        "df['Partner'] = df['Partner'].map({'Yes': 1, 'No': 0})\n",
        "df['Dependents'] = df['Dependents'].map({'Yes': 1, 'No': 0})\n",
        "df['PhoneService'] = df['PhoneService'].map({'Yes': 1, 'No': 0})\n",
        "df['MultipleLines'] = df['MultipleLines'].map({'Yes': 1, 'No': 0, 'No phone service': 0})\n",
        "df['OnlineSecurity'] = df['OnlineSecurity'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['OnlineBackup'] = df['OnlineBackup'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['DeviceProtection'] = df['DeviceProtection'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['TechSupport'] = df['TechSupport'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['StreamingTV'] = df['StreamingTV'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['StreamingMovies'] = df['StreamingMovies'].map({'Yes': 1, 'No': 0, 'No internet service': 0})\n",
        "df['PaperlessBilling'] = df['PaperlessBilling'].map({'Yes': 1, 'No': 0})\n",
        "df['gender'] = df['gender'].map({'Male': 1, 'Female': 0})\n",
        "df['PaymentMethod'] = df['PaymentMethod'].map({'Electronic check': 2, 'Mailed check': 1, 'Bank transfer (automatic)': 4, 'Credit card (automatic)': 3})\n",
        "df['InternetService'] = df['InternetService'].map({'Fiber optic': 2, 'DSL': 1, 'No':0})\n",
        "services = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
        "            'StreamingTV', 'StreamingMovies']\n",
        "df['num_services'] = df[services].sum(axis=1)\n",
        "df['revenue_proxy'] = df['MonthlyCharges'] * df['tenure']\n",
        "df['contract_tenure'] = df['Contract'] * df['tenure']\n",
        "df['tenure_squared'] = df['tenure'] ** 2\n",
        "df['tenure_cubed'] = df['tenure'] ** 3\n",
        "df['is_MTM'] = (df['Contract'] == 3).astype(int) # Assuming 3 represents Month-to-month\n",
        "df['high_charge'] = (df['MonthlyCharges'] > df['MonthlyCharges'].mean()).astype(int)\n",
        "df['MTM_high_charge'] = df['is_MTM'] * df['high_charge']\n",
        "df['log_TotalCharges'] = np.log1p(df['TotalCharges'])\n",
        "df['log_tenure'] = np.log1p(df['tenure'])\n",
        "df['log_MonthlyCharges'] = np.log1p(df['MonthlyCharges'])\n",
        "df['log_num_services'] = np.log1p(df['num_services'])\n",
        "df['log_revenue_proxy'] = np.log1p(df['revenue_proxy'])\n",
        "df['log_contract_tenure'] = np.log1p(df['contract_tenure'])\n",
        "df['log_MTM_high_charge'] = np.log1p(df['MTM_high_charge'])\n",
        "df['log_age'] = np.log1p(df['SeniorCitizen'])\n",
        "X_test = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8gYwSMbZ31TZ"
      },
      "outputs": [],
      "source": [
        "def finalmodel1(X_train, X_test, y_train):\n",
        "    log_reg = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, solver = 'saga', penalty = 'l1'))\n",
        "    log_reg2 = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, class_weight= 'balanced', solver = 'saga', penalty = 'l1'))\n",
        "    alpha = 0.8\n",
        "    beta = 0.5\n",
        "    trained_model = train_model(X_train, y_train, log_reg)\n",
        "    trained_model2 = train_model(X_train, y_train, log_reg2)\n",
        "    y_train_probs1 = trained_model.predict_proba(X_train)[:, 1]\n",
        "    y_train_probs2 = trained_model2.predict_proba(X_train)[:, 1]\n",
        "    y_train_probs = (alpha * y_train_probs1 + beta * y_train_probs2) / 2\n",
        "\n",
        "    y_probs1 = trained_model.predict_proba(X_test)[:, 1]\n",
        "    y_probs2 = trained_model2.predict_proba(X_test)[:, 1]\n",
        "    y_probs = ( alpha * y_probs1 + beta * y_probs2) / 2\n",
        "\n",
        "\n",
        "    threshold = 0.2141 \n",
        "    y_pred = (y_probs >= threshold).astype(int)\n",
        "    y_pred = pd.Series(y_pred).map({1: 'Yes', 0: 'No'})\n",
        "    output_df = pd.DataFrame({'customerID': customerID, 'Churn': y_pred})\n",
        "    output_df.to_csv('submission.csv', index=False)\n",
        "    \n",
        "finalmodel1(X, X_test, y)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tGfm8Tsl0Pxe"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
